{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-14 13:46:57,996 - INFO - Dataset dataset_2016_senior_players.csv loaded successfully.\n",
      "2024-08-14 13:46:57,997 - INFO - Columns in the 2016 senior dataset: ['name', 'position', 'group', 'club', 'division', 'based_in', 'division_tier', 'tier_quality', 'date_of_birth', 'birth_month', 'birth_quarter', 'age_(days)_on_1_july_2015', 'age_(months)_on_1_july_2015', 'age_(years)_on_1_july_2015', 'birth_city', 'nation_of_birth', 'birth_region', 'nationality', 'second_nationality', 'height_(ft_in)', 'height_(ft)', 'height_(in)', 'height_(cm)', 'weight_(kg)', 'goals', 'appearances', 'is_top_4_tier', 'train_or_test']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/miniconda3/lib/python3.12/site-packages/sklearn/model_selection/_search.py:320: UserWarning: The total space of parameters 24 is smaller than n_iter=100. Running 24 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   0.1s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   0.1s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   0.0s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   0.1s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   0.1s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.1s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.0s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.1s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.0s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.0s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=2, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=2, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=2, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=2, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=2, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.1s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.1s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.1s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.1s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.3s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=5, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.1s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=5, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=5, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=5, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=5, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.1s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.1s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.1s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   0.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   0.1s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   0.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   0.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   0.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-14 13:47:02,842 - INFO - Best parameters: {'n_estimators': 100, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_depth': 10}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/miniconda3/lib/python3.12/site-packages/sklearn/model_selection/_search.py:320: UserWarning: The total space of parameters 24 is smaller than n_iter=100. Running 24 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   0.0s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   0.1s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   0.0s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   0.1s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   0.1s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.1s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.1s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.1s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=2, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=2, n_estimators=10; total time=   0.1s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.1s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=2, n_estimators=10; total time=   0.1s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=2, n_estimators=10; total time=   0.1s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.4s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.5s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.2s[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=2, n_estimators=10; total time=   0.2s\n",
      "\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.5s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.3s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.3s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.6s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=5, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=5, n_estimators=10; total time=   0.1s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.1s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=5, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=5, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.3s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.1s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=5, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.2s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.1s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.1s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   0.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   0.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   0.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.1s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   0.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   0.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.1s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-14 13:47:04,713 - INFO - Best parameters: {'n_estimators': 50, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_depth': 10}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.1s\n",
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=10; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/miniconda3/lib/python3.12/site-packages/sklearn/model_selection/_search.py:320: UserWarning: The total space of parameters 24 is smaller than n_iter=100. Running 24 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "/Applications/miniconda3/lib/python3.12/site-packages/sklearn/model_selection/_split.py:776: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   0.0s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   0.1s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   0.1s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   0.0s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   0.1s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.0s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.1s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.1s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=2, n_estimators=10; total time=   0.1s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=2, n_estimators=10; total time=   0.1s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=2, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=2, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=2, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.1s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.1s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.1s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.1s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.1s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=5, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.1s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=5, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.0s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=5, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=5, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=5, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   0.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   0.0s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   0.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   0.0s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.0s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   0.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=10; total time=   0.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-14 13:47:05,905 - INFO - Best parameters: {'n_estimators': 100, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_depth': 10}\n",
      "2024-08-14 13:47:05,966 - INFO - Validation MSE Goals: 22\n",
      "2024-08-14 13:47:05,966 - INFO - Validation MSE Appearances: 704\n",
      "2024-08-14 13:47:05,967 - INFO - Validation Accuracy Tier Quality: 0.8275862068965517\n",
      "2024-08-14 13:47:05,971 - INFO - Validation Classification Report Tier Quality:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       1.00      0.75      0.86         4\n",
      "         3.0       1.00      0.56      0.71         9\n",
      "         4.0       0.70      1.00      0.82         7\n",
      "         5.0       0.83      1.00      0.91         5\n",
      "         7.0       0.80      1.00      0.89         4\n",
      "\n",
      "    accuracy                           0.83        29\n",
      "   macro avg       0.87      0.86      0.84        29\n",
      "weighted avg       0.87      0.83      0.82        29\n",
      "\n",
      "2024-08-14 13:47:05,980 - INFO - Dataset dataset_2016_youth_players.csv loaded successfully.\n",
      "2024-08-14 13:47:05,981 - INFO - Columns in the 2016 youth dataset: ['name', 'position', 'group', 'club', 'division', 'based_in', 'division_tier', 'tier_quality', 'date_of_birth', 'birth_month', 'birth_quarter', 'age_(days)_on_1_july_2015', 'age_(months)_on_1_july_2015', 'age_(years)_on_1_july_2015', 'birth_city', 'nation_of_birth', 'birth_region', 'nationality', 'second_nationality', 'height_(ft_in)', 'height_(ft)', 'height_(in)', 'height_(cm)', 'weight_(kg)', 'goals', 'appearances', 'is_top_4_tier', 'train_or_test']\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:27: UserWarning: Parsing dates in %d/%m/%Y format when dayfirst=False (the default) was specified. Pass `dayfirst=True` or specify a format to silence this warning.\n",
      "  data['date_of_birth'] = pd.to_datetime(data['date_of_birth'], errors='coerce')\n",
      "2024-08-14 13:47:06,028 - INFO - MSE Goals: 1\n",
      "2024-08-14 13:47:06,028 - INFO - MSE Appearances: 152\n",
      "2024-08-14 13:47:06,028 - INFO - Accuracy Tier Quality: 0.7897100857492855\n",
      "/Applications/miniconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Applications/miniconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Applications/miniconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "2024-08-14 13:47:06,034 - INFO - Test Classification Report Tier Quality:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.86      0.78      0.82       484\n",
      "           2       0.00      0.00      0.00         2\n",
      "           3       0.94      0.33      0.48       537\n",
      "           4       0.61      1.00      0.76       515\n",
      "           5       0.83      0.92      0.87       440\n",
      "           6       1.00      0.14      0.25        14\n",
      "           7       0.94      1.00      0.97       457\n",
      "\n",
      "    accuracy                           0.79      2449\n",
      "   macro avg       0.74      0.60      0.59      2449\n",
      "weighted avg       0.83      0.79      0.77      2449\n",
      "\n",
      "2024-08-14 13:47:06,042 - INFO - Feature importances for goals (as percentages): {'division': '6.43', 'division_tier': '5.96', 'birth_month': '3.50', 'birth_quarter': '4.38', 'age_(days)_on_1_july_2015': '12.49', 'age_(months)_on_1_july_2015': '6.60', 'age_(years)_on_1_july_2015': '8.88', 'height_(ft_in)': '0.00', 'height_(ft)': '0.00', 'height_(in)': '0.00', 'height_(cm)': '6.18', 'weight_(kg)': '7.25', 'is_top_4_tier': '0.00', 'train_or_test': '0.00', 'based_in_ENG': '0.10', 'based_in_ESP': '0.00', 'based_in_SCO': '0.10', 'birth_city_Aldershot': '0.00', 'birth_city_Ascot': '0.00', 'birth_city_Ashford': '0.00', 'birth_city_Ashington': '0.00', 'birth_city_AshtonNaNunderNaNLyne': '0.00', 'birth_city_BarrowNaNinNaNFurness': '0.00', 'birth_city_Beverley': '0.00', 'birth_city_Biddulph': '0.00', 'birth_city_Birmingham': '0.02', 'birth_city_Blackpool': '0.00', 'birth_city_Bolton': '0.00', 'birth_city_Bournemouth': '0.00', 'birth_city_Bristol': '0.00', 'birth_city_Bromley': '0.00', 'birth_city_Burnley': '0.00', 'birth_city_Cambridge': '0.00', 'birth_city_Carlisle': '0.00', 'birth_city_Chesterfield': '0.00', 'birth_city_Coventry': '0.00', 'birth_city_Derby': '0.00', 'birth_city_Doncaster': '0.00', 'birth_city_Droylsden': '0.00', 'birth_city_Edgbaston': '0.00', 'birth_city_Enfield': '0.00', 'birth_city_Exeter': '0.00', 'birth_city_Gloucester': '0.00', 'birth_city_Guildford': '0.00', 'birth_city_Hayes': '0.00', 'birth_city_Huddersfield': '0.00', 'birth_city_Ipswich': '0.00', 'birth_city_Keighley': '0.00', 'birth_city_Kingston upon Thames': '0.00', 'birth_city_Lancaster': '0.00', 'birth_city_Leeds': '0.00', 'birth_city_Leyton': '0.00', 'birth_city_Lincoln': '0.00', 'birth_city_Liverpool': '0.00', 'birth_city_London': '7.53', 'birth_city_Luton': '0.00', 'birth_city_Macclesfield': '0.00', 'birth_city_Manchester': '0.07', 'birth_city_Melton Mowbray': '0.00', 'birth_city_Middlesbrough': '0.01', 'birth_city_Milton Keynes': '0.00', 'birth_city_Newcastle': '0.00', 'birth_city_Newport (Isle of Wight)': '0.00', 'birth_city_Northampton': '0.00', 'birth_city_Oxford': '0.26', 'birth_city_Paulton': '0.00', 'birth_city_Plymouth': '0.00', 'birth_city_Poole': '0.00', 'birth_city_Portsmouth': '0.00', 'birth_city_Preston': '0.00', 'birth_city_Reading': '0.00', 'birth_city_Rotherham': '0.00', 'birth_city_Salford': '0.00', 'birth_city_Sheffield': '0.02', 'birth_city_Solihull': '0.45', 'birth_city_South Shields': '0.00', 'birth_city_Stevenage': '0.00', 'birth_city_StokeNaNonNaNTrent': '0.00', 'birth_city_Sunderland': '0.00', 'birth_city_Wakefield': '0.00', 'birth_city_Warrington': '0.00', 'birth_city_Warwick': '0.00', 'birth_city_Welwyn Garden City': '0.00', 'birth_city_West Bromwich': '0.00', 'birth_city_Whitehaven': '0.00', 'birth_city_Winchester': '0.00', 'nation_of_birth_ENG': '0.00', 'birth_region_UK & Ireland': '0.00', 'nationality_ENG': '0.00', 'position_AM (C)': '2.14', 'position_AM (L)': '0.00', 'position_AM (L), ST (C)': '0.00', 'position_AM (LC)': '0.00', 'position_AM (R)': '0.06', 'position_AM (RL)': '0.00', 'position_AM (RL), ST (C)': '2.99', 'position_AM (RLC)': '0.00', 'position_AM (RLC), ST (C)': '0.00', 'position_D (C)': '0.02', 'position_D (L)': '0.07', 'position_D (LC)': '0.00', 'position_D (R)': '0.01', 'position_D (R), DM': '0.00', 'position_D (RL)': '0.00', 'position_D/M (L)': '0.00', 'position_D/WB (L)': '0.01', 'position_D/WB (R), M (RC)': '0.00', 'position_D/WB/AM (L)': '0.00', 'position_D/WB/M/AM (L)': '0.00', 'position_DM': '0.00', 'position_DM, M (C)': '0.00', 'position_GK': '0.10', 'position_M (C)': '0.48', 'position_M (C), AM (LC)': '0.00', 'position_M (C), AM (RC)': '0.48', 'position_M (L)': '0.00', 'position_M (L), AM (LC)': '0.00', 'position_M (L), AM (RL)': '0.00', 'position_M (LC)': '0.00', 'position_M (R), AM (RLC)': '0.00', 'position_M (RC)': '0.00', 'position_M (RL), AM (RLC)': '0.00', 'position_M/AM (C)': '0.02', 'position_M/AM (R)': '0.89', 'position_M/AM (RC)': '0.00', 'position_ST (C)': '3.93', 'group_Defender': '1.28', 'group_Forward': '5.51', 'group_Goalkeeper': '0.26', 'group_Midfielder': '1.22', 'club_AFC Wimbledon': '0.00', 'club_Aldershot': '0.00', 'club_Aston Villa': '0.00', 'club_Barnet': '0.50', 'club_Barnsley': '0.03', 'club_Barrow': '0.00', 'club_Bolton': '0.00', 'club_Bournemouth': '0.18', 'club_Bradford City': '0.45', 'club_Braintree': '0.00', 'club_Brentford': '0.00', 'club_Bristol Rovers': '0.00', 'club_Cambridge': '0.00', 'club_Carlisle': '0.00', 'club_Chelsea': '0.00', 'club_Cheltenham': '0.00', 'club_Cirencester': '0.00', 'club_Colchester': '0.00', 'club_Coventry': '0.00', 'club_Crewe': '0.00', 'club_Doncaster': '0.00', 'club_Dundee Utd': '0.00', 'club_FC Halifax': '0.00', 'club_Fleetwood': '0.00', 'club_Forest Green': '0.00', 'club_Gillingham': '0.00', 'club_Guiseley': '0.00', 'club_Hartlepool': '0.00', 'club_Hayes & Yeading': '0.00', 'club_Hednesford': '0.00', 'club_Holbeach': '0.00', 'club_Hrcules': '0.00', 'club_Ilkeston': '0.00', 'club_Inverness CT': '0.00', 'club_Kidderminster': '0.01', 'club_Leeds': '0.00', 'club_Leyton Orient': '0.00', 'club_Lincoln': '3.31', 'club_Luton': '0.00', 'club_MK Dons': '0.00', 'club_Macclesfield': '0.00', 'club_Man City': '0.00', 'club_Man Utd': '0.01', 'club_Mansfield': '0.00', 'club_Middlesbrough': '0.00', 'club_Millwall': '0.34', 'club_Morecambe': '0.00', 'club_Newcastle': '2.64', 'club_Newport Co': '0.00', 'club_Nottm Forest': '0.00', 'club_Notts Co': '0.00', 'club_Oldham': '0.00', 'club_Oxford': '0.00', 'club_Plymouth': '0.00', 'club_Port Vale': '0.00', 'club_Portsmouth': '0.00', 'club_Preston': '0.00', 'club_Q.P.R.': '0.00', 'club_Queen of Sth': '0.00', 'club_Rangers': '0.00', 'club_Reading': '0.15', 'club_Rochdale': '0.00', 'club_Rotherham': '0.00', 'club_Scunthorpe': '0.00', 'club_Sheff Utd': '0.53', 'club_Sheff Wed': '0.00', 'club_Southampton': '0.00', 'club_Southend': '0.00', 'club_Stevenage': '0.00', 'club_Stoke': '0.00', 'club_Sunderland': '0.00', 'club_Swansea': '0.29', 'club_Swindon': '0.00', 'club_Torquay': '0.00', 'club_Tottenham': '0.60', 'club_Tranmere': '0.00', 'club_Walsall': '0.04', 'club_Welling': '0.03', 'club_Wigan': '0.00', 'club_Wolves': '0.00', 'club_Yeovil': '0.00', 'second_nationality_CIV': '0.00', 'second_nationality_GHA': '0.00', 'second_nationality_IRL': '0.00', 'second_nationality_ITA': '0.00', 'second_nationality_JAM': '0.00', 'second_nationality_MLT': '0.00', 'second_nationality_NGA': '1.19', 'second_nationality_NIR': '0.00', 'second_nationality_PAK': '0.00', 'second_nationality_POL': '0.00', 'second_nationality_SCO': '0.01', 'second_nationality_TUR': '0.00', 'second_nationality_UGA': '0.00'}\n",
      "2024-08-14 13:47:06,042 - INFO - Feature importances for appearances (as percentages): {'division': '2.16', 'division_tier': '5.74', 'birth_month': '5.85', 'birth_quarter': '2.36', 'age_(days)_on_1_july_2015': '16.74', 'age_(months)_on_1_july_2015': '7.24', 'age_(years)_on_1_july_2015': '23.98', 'height_(ft_in)': '0.00', 'height_(ft)': '0.00', 'height_(in)': '0.00', 'height_(cm)': '4.76', 'weight_(kg)': '7.21', 'is_top_4_tier': '0.00', 'train_or_test': '0.00', 'based_in_ENG': '0.00', 'based_in_ESP': '0.00', 'based_in_SCO': '0.00', 'birth_city_Aldershot': '0.00', 'birth_city_Ascot': '0.00', 'birth_city_Ashford': '0.00', 'birth_city_Ashington': '0.00', 'birth_city_AshtonNaNunderNaNLyne': '0.00', 'birth_city_BarrowNaNinNaNFurness': '0.00', 'birth_city_Beverley': '0.00', 'birth_city_Biddulph': '0.00', 'birth_city_Birmingham': '0.00', 'birth_city_Blackpool': '0.00', 'birth_city_Bolton': '0.00', 'birth_city_Bournemouth': '0.00', 'birth_city_Bristol': '0.00', 'birth_city_Bromley': '0.00', 'birth_city_Burnley': '0.00', 'birth_city_Cambridge': '0.00', 'birth_city_Carlisle': '0.00', 'birth_city_Chesterfield': '0.00', 'birth_city_Coventry': '0.00', 'birth_city_Derby': '0.00', 'birth_city_Doncaster': '0.00', 'birth_city_Droylsden': '0.00', 'birth_city_Edgbaston': '0.00', 'birth_city_Enfield': '0.00', 'birth_city_Exeter': '0.00', 'birth_city_Gloucester': '0.00', 'birth_city_Guildford': '0.00', 'birth_city_Hayes': '0.00', 'birth_city_Huddersfield': '0.00', 'birth_city_Ipswich': '0.00', 'birth_city_Keighley': '0.00', 'birth_city_Kingston upon Thames': '0.43', 'birth_city_Lancaster': '0.00', 'birth_city_Leeds': '0.00', 'birth_city_Leyton': '0.00', 'birth_city_Lincoln': '0.00', 'birth_city_Liverpool': '0.00', 'birth_city_London': '1.86', 'birth_city_Luton': '0.00', 'birth_city_Macclesfield': '0.00', 'birth_city_Manchester': '0.01', 'birth_city_Melton Mowbray': '0.00', 'birth_city_Middlesbrough': '0.00', 'birth_city_Milton Keynes': '0.00', 'birth_city_Newcastle': '0.00', 'birth_city_Newport (Isle of Wight)': '0.00', 'birth_city_Northampton': '0.00', 'birth_city_Oxford': '0.00', 'birth_city_Paulton': '0.00', 'birth_city_Plymouth': '0.00', 'birth_city_Poole': '0.00', 'birth_city_Portsmouth': '0.00', 'birth_city_Preston': '0.00', 'birth_city_Reading': '0.00', 'birth_city_Rotherham': '0.00', 'birth_city_Salford': '0.00', 'birth_city_Sheffield': '0.04', 'birth_city_Solihull': '0.50', 'birth_city_South Shields': '0.00', 'birth_city_Stevenage': '0.00', 'birth_city_StokeNaNonNaNTrent': '0.00', 'birth_city_Sunderland': '0.00', 'birth_city_Wakefield': '0.00', 'birth_city_Warrington': '0.00', 'birth_city_Warwick': '0.00', 'birth_city_Welwyn Garden City': '0.00', 'birth_city_West Bromwich': '0.00', 'birth_city_Whitehaven': '0.00', 'birth_city_Winchester': '0.00', 'nation_of_birth_ENG': '0.00', 'birth_region_UK & Ireland': '0.00', 'nationality_ENG': '0.00', 'position_AM (C)': '0.00', 'position_AM (L)': '0.00', 'position_AM (L), ST (C)': '0.00', 'position_AM (LC)': '0.00', 'position_AM (R)': '0.00', 'position_AM (RL)': '0.00', 'position_AM (RL), ST (C)': '0.00', 'position_AM (RLC)': '0.00', 'position_AM (RLC), ST (C)': '0.00', 'position_D (C)': '0.39', 'position_D (L)': '0.16', 'position_D (LC)': '0.00', 'position_D (R)': '0.03', 'position_D (R), DM': '0.00', 'position_D (RL)': '0.00', 'position_D/M (L)': '0.00', 'position_D/WB (L)': '1.21', 'position_D/WB (R), M (RC)': '0.00', 'position_D/WB/AM (L)': '0.00', 'position_D/WB/M/AM (L)': '0.00', 'position_DM': '0.00', 'position_DM, M (C)': '0.00', 'position_GK': '0.54', 'position_M (C)': '0.26', 'position_M (C), AM (LC)': '0.00', 'position_M (C), AM (RC)': '0.00', 'position_M (L)': '0.00', 'position_M (L), AM (LC)': '0.00', 'position_M (L), AM (RL)': '0.00', 'position_M (LC)': '0.00', 'position_M (R), AM (RLC)': '0.00', 'position_M (RC)': '0.00', 'position_M (RL), AM (RLC)': '0.00', 'position_M/AM (C)': '0.00', 'position_M/AM (R)': '0.81', 'position_M/AM (RC)': '0.00', 'position_ST (C)': '0.57', 'group_Defender': '1.25', 'group_Forward': '0.94', 'group_Goalkeeper': '0.30', 'group_Midfielder': '0.65', 'club_AFC Wimbledon': '0.00', 'club_Aldershot': '0.00', 'club_Aston Villa': '0.00', 'club_Barnet': '1.98', 'club_Barnsley': '0.00', 'club_Barrow': '0.52', 'club_Bolton': '0.00', 'club_Bournemouth': '0.00', 'club_Bradford City': '0.00', 'club_Braintree': '0.00', 'club_Brentford': '0.00', 'club_Bristol Rovers': '0.00', 'club_Cambridge': '0.00', 'club_Carlisle': '0.00', 'club_Chelsea': '0.00', 'club_Cheltenham': '0.00', 'club_Cirencester': '0.00', 'club_Colchester': '0.03', 'club_Coventry': '0.00', 'club_Crewe': '0.00', 'club_Doncaster': '0.00', 'club_Dundee Utd': '0.00', 'club_FC Halifax': '0.00', 'club_Fleetwood': '0.00', 'club_Forest Green': '0.00', 'club_Gillingham': '0.00', 'club_Guiseley': '0.00', 'club_Hartlepool': '0.00', 'club_Hayes & Yeading': '0.00', 'club_Hednesford': '0.00', 'club_Holbeach': '0.00', 'club_Hrcules': '0.00', 'club_Ilkeston': '0.00', 'club_Inverness CT': '0.00', 'club_Kidderminster': '0.00', 'club_Leeds': '0.00', 'club_Leyton Orient': '0.00', 'club_Lincoln': '0.30', 'club_Luton': '0.00', 'club_MK Dons': '0.00', 'club_Macclesfield': '0.00', 'club_Man City': '0.10', 'club_Man Utd': '0.13', 'club_Mansfield': '0.00', 'club_Middlesbrough': '0.00', 'club_Millwall': '0.08', 'club_Morecambe': '0.00', 'club_Newcastle': '0.26', 'club_Newport Co': '0.00', 'club_Nottm Forest': '0.00', 'club_Notts Co': '0.00', 'club_Oldham': '0.00', 'club_Oxford': '0.00', 'club_Plymouth': '0.00', 'club_Port Vale': '0.00', 'club_Portsmouth': '0.00', 'club_Preston': '0.00', 'club_Q.P.R.': '0.00', 'club_Queen of Sth': '0.00', 'club_Rangers': '0.00', 'club_Reading': '9.71', 'club_Rochdale': '0.00', 'club_Rotherham': '0.00', 'club_Scunthorpe': '0.00', 'club_Sheff Utd': '0.00', 'club_Sheff Wed': '0.00', 'club_Southampton': '0.00', 'club_Southend': '0.00', 'club_Stevenage': '0.00', 'club_Stoke': '0.00', 'club_Sunderland': '0.00', 'club_Swansea': '0.17', 'club_Swindon': '0.00', 'club_Torquay': '0.05', 'club_Tottenham': '0.00', 'club_Tranmere': '0.00', 'club_Walsall': '0.00', 'club_Welling': '0.07', 'club_Wigan': '0.00', 'club_Wolves': '0.00', 'club_Yeovil': '0.00', 'second_nationality_CIV': '0.00', 'second_nationality_GHA': '0.00', 'second_nationality_IRL': '0.00', 'second_nationality_ITA': '0.00', 'second_nationality_JAM': '0.00', 'second_nationality_MLT': '0.00', 'second_nationality_NGA': '0.60', 'second_nationality_NIR': '0.00', 'second_nationality_PAK': '0.00', 'second_nationality_POL': '0.00', 'second_nationality_SCO': '0.00', 'second_nationality_TUR': '0.00', 'second_nationality_UGA': '0.00'}\n",
      "2024-08-14 13:47:06,043 - INFO - Feature importances for tier quality (as percentages): {'division': '22.93', 'division_tier': '18.26', 'birth_month': '2.28', 'birth_quarter': '2.75', 'age_(days)_on_1_july_2015': '2.44', 'age_(months)_on_1_july_2015': '2.20', 'age_(years)_on_1_july_2015': '1.74', 'height_(ft_in)': '0.00', 'height_(ft)': '0.00', 'height_(in)': '0.00', 'height_(cm)': '2.65', 'weight_(kg)': '3.82', 'is_top_4_tier': '0.00', 'train_or_test': '0.00', 'based_in_ENG': '0.98', 'based_in_ESP': '0.01', 'based_in_SCO': '0.91', 'birth_city_Aldershot': '0.14', 'birth_city_Ascot': '0.00', 'birth_city_Ashford': '0.12', 'birth_city_Ashington': '0.00', 'birth_city_AshtonNaNunderNaNLyne': '0.03', 'birth_city_BarrowNaNinNaNFurness': '0.16', 'birth_city_Beverley': '0.00', 'birth_city_Biddulph': '0.23', 'birth_city_Birmingham': '0.24', 'birth_city_Blackpool': '0.04', 'birth_city_Bolton': '0.07', 'birth_city_Bournemouth': '0.12', 'birth_city_Bristol': '0.00', 'birth_city_Bromley': '0.04', 'birth_city_Burnley': '0.00', 'birth_city_Cambridge': '0.21', 'birth_city_Carlisle': '0.12', 'birth_city_Chesterfield': '0.09', 'birth_city_Coventry': '0.01', 'birth_city_Derby': '0.00', 'birth_city_Doncaster': '0.10', 'birth_city_Droylsden': '0.04', 'birth_city_Edgbaston': '0.04', 'birth_city_Enfield': '0.02', 'birth_city_Exeter': '0.04', 'birth_city_Gloucester': '0.00', 'birth_city_Guildford': '0.03', 'birth_city_Hayes': '0.17', 'birth_city_Huddersfield': '0.00', 'birth_city_Ipswich': '0.06', 'birth_city_Keighley': '0.03', 'birth_city_Kingston upon Thames': '0.32', 'birth_city_Lancaster': '0.20', 'birth_city_Leeds': '0.09', 'birth_city_Leyton': '0.00', 'birth_city_Lincoln': '0.11', 'birth_city_Liverpool': '0.21', 'birth_city_London': '0.60', 'birth_city_Luton': '0.04', 'birth_city_Macclesfield': '0.05', 'birth_city_Manchester': '0.21', 'birth_city_Melton Mowbray': '0.04', 'birth_city_Middlesbrough': '0.66', 'birth_city_Milton Keynes': '0.09', 'birth_city_Newcastle': '0.11', 'birth_city_Newport (Isle of Wight)': '0.05', 'birth_city_Northampton': '0.09', 'birth_city_Oxford': '0.32', 'birth_city_Paulton': '0.00', 'birth_city_Plymouth': '0.00', 'birth_city_Poole': '0.00', 'birth_city_Portsmouth': '0.18', 'birth_city_Preston': '0.12', 'birth_city_Reading': '0.02', 'birth_city_Rotherham': '0.18', 'birth_city_Salford': '0.00', 'birth_city_Sheffield': '0.16', 'birth_city_Solihull': '0.10', 'birth_city_South Shields': '0.00', 'birth_city_Stevenage': '0.11', 'birth_city_StokeNaNonNaNTrent': '0.13', 'birth_city_Sunderland': '0.30', 'birth_city_Wakefield': '0.05', 'birth_city_Warrington': '0.03', 'birth_city_Warwick': '0.14', 'birth_city_Welwyn Garden City': '0.00', 'birth_city_West Bromwich': '0.11', 'birth_city_Whitehaven': '0.13', 'birth_city_Winchester': '0.08', 'nation_of_birth_ENG': '0.00', 'birth_region_UK & Ireland': '0.00', 'nationality_ENG': '0.00', 'position_AM (C)': '0.04', 'position_AM (L)': '0.13', 'position_AM (L), ST (C)': '0.13', 'position_AM (LC)': '0.00', 'position_AM (R)': '0.15', 'position_AM (RL)': '0.07', 'position_AM (RL), ST (C)': '0.11', 'position_AM (RLC)': '0.03', 'position_AM (RLC), ST (C)': '0.07', 'position_D (C)': '0.26', 'position_D (L)': '0.44', 'position_D (LC)': '0.21', 'position_D (R)': '0.17', 'position_D (R), DM': '0.04', 'position_D (RL)': '0.00', 'position_D/M (L)': '0.22', 'position_D/WB (L)': '0.23', 'position_D/WB (R), M (RC)': '0.04', 'position_D/WB/AM (L)': '0.19', 'position_D/WB/M/AM (L)': '0.12', 'position_DM': '0.00', 'position_DM, M (C)': '0.36', 'position_GK': '0.57', 'position_M (C)': '0.76', 'position_M (C), AM (LC)': '0.07', 'position_M (C), AM (RC)': '0.25', 'position_M (L)': '0.10', 'position_M (L), AM (LC)': '0.11', 'position_M (L), AM (RL)': '0.23', 'position_M (LC)': '0.05', 'position_M (R), AM (RLC)': '0.06', 'position_M (RC)': '0.05', 'position_M (RL), AM (RLC)': '0.06', 'position_M/AM (C)': '0.04', 'position_M/AM (R)': '0.06', 'position_M/AM (RC)': '0.23', 'position_ST (C)': '0.50', 'group_Defender': '0.70', 'group_Forward': '0.33', 'group_Goalkeeper': '0.28', 'group_Midfielder': '0.73', 'club_AFC Wimbledon': '0.42', 'club_Aldershot': '0.06', 'club_Aston Villa': '0.19', 'club_Barnet': '1.23', 'club_Barnsley': '0.73', 'club_Barrow': '0.32', 'club_Bolton': '0.14', 'club_Bournemouth': '1.56', 'club_Bradford City': '0.31', 'club_Braintree': '0.00', 'club_Brentford': '0.10', 'club_Bristol Rovers': '0.03', 'club_Cambridge': '0.13', 'club_Carlisle': '0.76', 'club_Chelsea': '0.00', 'club_Cheltenham': '0.04', 'club_Cirencester': '0.00', 'club_Colchester': '0.47', 'club_Coventry': '0.37', 'club_Crewe': '0.02', 'club_Doncaster': '0.16', 'club_Dundee Utd': '0.00', 'club_FC Halifax': '0.08', 'club_Fleetwood': '0.05', 'club_Forest Green': '0.00', 'club_Gillingham': '0.00', 'club_Guiseley': '0.12', 'club_Hartlepool': '0.11', 'club_Hayes & Yeading': '0.08', 'club_Hednesford': '0.09', 'club_Holbeach': '0.02', 'club_Hrcules': '0.06', 'club_Ilkeston': '0.20', 'club_Inverness CT': '0.11', 'club_Kidderminster': '0.47', 'club_Leeds': '0.00', 'club_Leyton Orient': '0.00', 'club_Lincoln': '0.38', 'club_Luton': '0.05', 'club_MK Dons': '0.00', 'club_Macclesfield': '0.03', 'club_Man City': '0.90', 'club_Man Utd': '0.78', 'club_Mansfield': '0.11', 'club_Middlesbrough': '0.57', 'club_Millwall': '0.64', 'club_Morecambe': '0.04', 'club_Newcastle': '0.30', 'club_Newport Co': '0.00', 'club_Nottm Forest': '0.17', 'club_Notts Co': '0.08', 'club_Oldham': '0.13', 'club_Oxford': '0.10', 'club_Plymouth': '0.42', 'club_Port Vale': '0.07', 'club_Portsmouth': '0.45', 'club_Preston': '0.32', 'club_Q.P.R.': '0.24', 'club_Queen of Sth': '0.51', 'club_Rangers': '0.36', 'club_Reading': '0.46', 'club_Rochdale': '0.00', 'club_Rotherham': '0.47', 'club_Scunthorpe': '0.05', 'club_Sheff Utd': '0.76', 'club_Sheff Wed': '1.43', 'club_Southampton': '0.69', 'club_Southend': '0.08', 'club_Stevenage': '0.21', 'club_Stoke': '0.04', 'club_Sunderland': '0.13', 'club_Swansea': '0.87', 'club_Swindon': '0.00', 'club_Torquay': '0.24', 'club_Tottenham': '0.59', 'club_Tranmere': '0.00', 'club_Walsall': '0.63', 'club_Welling': '0.22', 'club_Wigan': '0.03', 'club_Wolves': '0.11', 'club_Yeovil': '0.10', 'second_nationality_CIV': '0.17', 'second_nationality_GHA': '0.00', 'second_nationality_IRL': '0.16', 'second_nationality_ITA': '0.00', 'second_nationality_JAM': '0.07', 'second_nationality_MLT': '0.03', 'second_nationality_NGA': '0.54', 'second_nationality_NIR': '0.10', 'second_nationality_PAK': '0.04', 'second_nationality_POL': '0.05', 'second_nationality_SCO': '0.34', 'second_nationality_TUR': '0.00', 'second_nationality_UGA': '0.00'}\n",
      "2024-08-14 13:47:06,051 - INFO - Predictions have been saved to 'predictions_2016_youth.csv'.\n",
      "2024-08-14 13:47:06,060 - INFO - Dataset dataset_2024_senior_players.csv loaded successfully.\n",
      "2024-08-14 13:47:06,060 - INFO - Columns in the 2024 senior dataset: ['name', 'position', 'group', 'club', 'division', 'based_in', 'division_tier', 'tier_quality', 'date_of_birth', 'birth_month', 'birth_quarter', 'age_(days)_on_1_july_2023', 'age_(months)_on_1_july_2023', 'age_(years)_on_1_july_2023', 'birth_city', 'nation_of_birth', 'birth_region', 'nationality', 'second_nationality', 'height_(cm)', 'weight_(kg)', 'goals', 'appearances', 'is_top_4_tier']\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:27: UserWarning: Parsing dates in %d/%m/%Y format when dayfirst=False (the default) was specified. Pass `dayfirst=True` or specify a format to silence this warning.\n",
      "  data['date_of_birth'] = pd.to_datetime(data['date_of_birth'], errors='coerce')\n",
      "/Applications/miniconda3/lib/python3.12/site-packages/sklearn/model_selection/_search.py:320: UserWarning: The total space of parameters 24 is smaller than n_iter=100. Running 24 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=10; total time=   0.1s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=10; total time=   0.1s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=10; total time=   0.1s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=10; total time=   0.2s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=10; total time=   0.1s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   0.4s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   0.4s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   0.5s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   0.5s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=10; total time=   0.1s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=10; total time=   0.1s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   0.6s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=10; total time=   0.1s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=10; total time=   0.1s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=10; total time=   0.1s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.9s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.9s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.4s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   1.1s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.4s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.4s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=2, n_estimators=10; total time=   0.1s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.9s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=2, n_estimators=10; total time=   0.1s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=2, n_estimators=10; total time=   0.1s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=2, n_estimators=10; total time=   0.1s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   1.0s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=2, n_estimators=10; total time=   0.1s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.4s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.6s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.9s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.4s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.4s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.9s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.4s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.8s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=5, n_estimators=10; total time=   0.1s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=5, n_estimators=10; total time=   0.1s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.4s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=5, n_estimators=10; total time=   0.1s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.5s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=5, n_estimators=10; total time=   0.1s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.9s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   1.0s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.4s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.9s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.8s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.9s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=5, n_estimators=10; total time=   0.1s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.4s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=10; total time=   0.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=10; total time=   0.1s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.5s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=10; total time=   0.1s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.8s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.5s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=10; total time=   0.2s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=10; total time=   0.2s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.9s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.9s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.9s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.9s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   0.7s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   0.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   1.0s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.7s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   1.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=10; total time=   0.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=10; total time=   0.3s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=10; total time=   0.2s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=10; total time=   0.2s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   1.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   0.9s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   1.6s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   1.9s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   1.6s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.7s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.6s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=10; total time=   0.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.7s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=10; total time=   0.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=10; total time=   0.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=10; total time=   0.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.6s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=10; total time=   0.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=10; total time=   0.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   1.3s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.7s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   1.3s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   1.3s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   1.5s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.6s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   1.3s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.7s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.7s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.6s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=10; total time=   0.2s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   1.3s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=10; total time=   0.2s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=10; total time=   0.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=10; total time=   0.2s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   1.3s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=10; total time=   0.2s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   1.3s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   1.3s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   1.3s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   1.2s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.6s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   1.3s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.7s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.7s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.5s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.7s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   1.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   1.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   1.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   1.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-14 13:47:16,248 - INFO - Best parameters: {'n_estimators': 50, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_depth': 10}\n",
      "/Applications/miniconda3/lib/python3.12/site-packages/sklearn/model_selection/_search.py:320: UserWarning: The total space of parameters 24 is smaller than n_iter=100. Running 24 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=10; total time=   0.1s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=10; total time=   0.1s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=10; total time=   0.1s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=10; total time=   0.1s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=10; total time=   0.1s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   0.5s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   0.5s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   0.5s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   0.5s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=10; total time=   0.1s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   0.6s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=10; total time=   0.1s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=10; total time=   0.1s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=10; total time=   0.1s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.9s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=10; total time=   0.2s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.9s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   1.0s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.5s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=2, n_estimators=10; total time=   0.1s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.4s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=2, n_estimators=10; total time=   0.1s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.9s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.9s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=2, n_estimators=10; total time=   0.1s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.4s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=2, n_estimators=10; total time=   0.1s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=2, n_estimators=10; total time=   0.1s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.4s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.5s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.8s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.9s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.5s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.4s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.4s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.4s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.4s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.9s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=5, n_estimators=10; total time=   0.1s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.8s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=5, n_estimators=10; total time=   0.1s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=5, n_estimators=10; total time=   0.1s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=5, n_estimators=10; total time=   0.1s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.8s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.9s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.9s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.4s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.9s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=5, n_estimators=10; total time=   0.1s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.5s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=10; total time=   0.1s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.6s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=10; total time=   0.1s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.8s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.6s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=10; total time=   0.2s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=10; total time=   0.1s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.8s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.4s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.9s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=10; total time=   0.2s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.9s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   1.3s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   1.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   1.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   1.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=10; total time=   0.2s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   1.3s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=10; total time=   0.2s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   1.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=10; total time=   0.2s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=10; total time=   0.2s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   0.9s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   2.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   0.9s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   1.9s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.7s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.9s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   1.9s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.9s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=10; total time=   0.2s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=10; total time=   0.2s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=10; total time=   0.2s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   1.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=10; total time=   0.2s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=10; total time=   0.2s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=10; total time=   0.2s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   1.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   1.7s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   1.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   1.9s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.7s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.9s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   1.7s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   1.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.9s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=10; total time=   0.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=10; total time=   0.2s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=10; total time=   0.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   1.6s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   1.7s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=10; total time=   0.2s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=10; total time=   0.2s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   1.6s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   1.6s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   1.6s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   1.7s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.7s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.7s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   1.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.7s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.7s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.7s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   1.3s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   1.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   1.3s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   1.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   1.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-14 13:47:28,767 - INFO - Best parameters: {'n_estimators': 100, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_depth': 10}\n",
      "/Applications/miniconda3/lib/python3.12/site-packages/sklearn/model_selection/_search.py:320: UserWarning: The total space of parameters 24 is smaller than n_iter=100. Running 24 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "/Applications/miniconda3/lib/python3.12/site-packages/sklearn/model_selection/_split.py:776: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   0.1s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   0.1s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   0.1s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   0.1s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   0.1s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.1s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.1s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.1s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=2, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=2, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.1s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=2, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=2, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=2, n_estimators=10; total time=   0.1s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.1s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.1s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.2s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.3s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.1s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=5, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.1s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=5, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.1s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=5, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=5, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.1s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.1s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=5, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   0.1s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   0.2s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   0.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   0.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   0.1s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.3s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.2s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.3s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-14 13:47:31,747 - INFO - Best parameters: {'n_estimators': 100, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_depth': 10}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-14 13:47:31,875 - INFO - Validation MSE Goals: 244\n",
      "2024-08-14 13:47:31,875 - INFO - Validation MSE Appearances: 2348\n",
      "2024-08-14 13:47:31,876 - INFO - Validation Accuracy Tier Quality: 0.8530259365994236\n",
      "/Applications/miniconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Applications/miniconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Applications/miniconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "2024-08-14 13:47:31,881 - INFO - Validation Classification Report Tier Quality:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      0.24      0.39        33\n",
      "           2       0.00      0.00      0.00         3\n",
      "           3       0.74      0.97      0.84        58\n",
      "           4       1.00      0.98      0.99        57\n",
      "           5       1.00      1.00      1.00        77\n",
      "           6       0.76      1.00      0.86        99\n",
      "           7       0.00      0.00      0.00        20\n",
      "\n",
      "    accuracy                           0.85       347\n",
      "   macro avg       0.64      0.60      0.58       347\n",
      "weighted avg       0.82      0.85      0.81       347\n",
      "\n",
      "2024-08-14 13:47:31,891 - INFO - Dataset dataset_2024_youth_players.csv loaded successfully.\n",
      "2024-08-14 13:47:31,891 - INFO - Columns in the 2024 youth dataset: ['name', 'position', 'group', 'club', 'division', 'based_in', 'division_tier', 'tier_quality', 'date_of_birth', 'birth_month', 'birth_quarter', 'age_(days)_on_1_july_2023', 'age_(months)_on_1_july_2023', 'age_(years)_on_1_july_2023', 'birth_city', 'nation_of_birth', 'birth_region', 'nationality', 'second_nationality', 'height_(cm)', 'weight_(kg)', 'goals', 'appearances', 'is_top_4_tier']\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:27: UserWarning: Parsing dates in %d/%m/%Y format when dayfirst=False (the default) was specified. Pass `dayfirst=True` or specify a format to silence this warning.\n",
      "  data['date_of_birth'] = pd.to_datetime(data['date_of_birth'], errors='coerce')\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "/var/folders/fs/2pw0dc014ls93dt5yfjzx6w00000gn/T/ipykernel_45875/2552989169.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = 0\n",
      "2024-08-14 13:47:32,042 - INFO - MSE Goals: 25\n",
      "2024-08-14 13:47:32,042 - INFO - MSE Appearances: 1050\n",
      "2024-08-14 13:47:32,042 - INFO - Accuracy Tier Quality: 0.40433624952453406\n",
      "/Applications/miniconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Applications/miniconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Applications/miniconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "2024-08-14 13:47:32,047 - INFO - Test Classification Report Tier Quality:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      0.19      0.32       572\n",
      "           2       0.00      0.00      0.00         2\n",
      "           3       0.13      0.12      0.12       571\n",
      "           4       0.47      1.00      0.64       447\n",
      "           5       0.86      1.00      0.93       379\n",
      "           6       0.10      0.50      0.17       122\n",
      "           7       0.00      0.00      0.00       536\n",
      "\n",
      "    accuracy                           0.40      2629\n",
      "   macro avg       0.37      0.40      0.31      2629\n",
      "weighted avg       0.45      0.40      0.35      2629\n",
      "\n",
      "2024-08-14 13:47:32,054 - INFO - Feature importances for goals (as percentages): {'division': '2.26', 'division_tier': '1.92', 'birth_month': '1.10', 'birth_quarter': '0.93', 'age_(days)_on_1_july_2023': '27.02', 'age_(months)_on_1_july_2023': '8.75', 'age_(years)_on_1_july_2023': '1.17', 'height_(cm)': '1.70', 'weight_(kg)': '2.32', 'is_top_4_tier': '0.16', 'based_in_AUS': '0.01', 'based_in_AUT': '0.00', 'based_in_BEL': '0.00', 'based_in_CAN': '0.02', 'based_in_CYP': '0.00', 'based_in_DEN': '0.00', 'based_in_ECU': '0.00', 'based_in_ENG': '0.10', 'based_in_ESP': '0.03', 'based_in_FIN': '0.00', 'based_in_FRA': '0.00', 'based_in_GER': '0.09', 'based_in_GRE': '0.01', 'based_in_HKG': '0.00', 'based_in_HUN': '0.00', 'based_in_IND': '0.00', 'based_in_IRL': '0.02', 'based_in_ISR': '0.00', 'based_in_ITA': '0.05', 'based_in_KSA': '0.00', 'based_in_MAS': '0.00', 'based_in_MDA': '0.00', 'based_in_NED': '0.00', 'based_in_NIR': '0.00', 'based_in_NOR': '0.00', 'based_in_POR': '0.01', 'based_in_QAT': '0.00', 'based_in_ROU': '0.00', 'based_in_RSA': '0.00', 'based_in_SCO': '0.03', 'based_in_SUI': '0.00', 'based_in_TUR': '0.00', 'based_in_USA': '0.03', 'based_in_WAL': '0.00', 'birth_city_Abidjan': '0.00', 'birth_city_Abingdon': '0.00', 'birth_city_Aldershot': '0.01', 'birth_city_Alsager': '0.01', 'birth_city_Altrincham': '0.00', 'birth_city_Amsterdam': '0.00', 'birth_city_Ascot': '0.01', 'birth_city_Ashford': '0.01', 'birth_city_Ashington': '0.01', 'birth_city_Aylesbury': '0.00', 'birth_city_Bacup': '0.00', 'birth_city_Banbury': '0.00', 'birth_city_Barking': '0.04', 'birth_city_Barnsley': '0.00', 'birth_city_BarrowNaNinNaNFurness': '0.00', 'birth_city_Basildon': '0.00', 'birth_city_Basingstoke': '0.00', 'birth_city_Bath': '0.00', 'birth_city_Bedford': '0.08', 'birth_city_BerwickNaNuponNaNTweed': '0.00', 'birth_city_Beverley': '0.03', 'birth_city_Biddulph': '0.00', 'birth_city_Billingham': '0.00', 'birth_city_Bilston': '0.00', 'birth_city_Birkenhead': '0.00', 'birth_city_Birmingham': '0.13', 'birth_city_Bishop Auckland': '0.00', \"birth_city_Bishop's Stortford\": '0.00', 'birth_city_Bissau': '0.00', 'birth_city_Blackburn': '0.00', 'birth_city_Blackpool': '0.00', 'birth_city_Blyth': '0.00', 'birth_city_Bognor Regis': '0.00', 'birth_city_Bolton': '0.02', 'birth_city_Bootle': '0.00', 'birth_city_Boston': '0.03', 'birth_city_Bournemouth': '0.02', 'birth_city_Bradford': '0.01', 'birth_city_Brentwood': '0.00', 'birth_city_Bridgwater': '0.00', 'birth_city_Bridlington': '0.00', 'birth_city_Brighton': '0.12', 'birth_city_Bristol': '0.02', 'birth_city_Bromley': '0.04', 'birth_city_Bromsgrove': '0.00', 'birth_city_Bunia': '0.00', 'birth_city_Burnley': '0.08', 'birth_city_Burscough': '0.00', 'birth_city_BurtonNaNonNaNTrent': '0.00', 'birth_city_Bury': '0.00', 'birth_city_Bury St. Edmunds': '0.00', 'birth_city_Calgary (AB)': '0.00', 'birth_city_Cambridge': '0.02', 'birth_city_Cannock': '0.00', 'birth_city_Canterbury': '0.00', 'birth_city_Cape Town': '0.00', 'birth_city_Carlisle': '0.00', 'birth_city_Carshalton': '0.00', 'birth_city_Chatham': '0.00', 'birth_city_Chelmsford': '0.03', 'birth_city_Cheltenham': '0.00', 'birth_city_Chertsey': '0.00', 'birth_city_Cheshunt': '0.00', 'birth_city_Chester': '0.00', 'birth_city_ChesterNaNleNaNStreet': '0.07', 'birth_city_Chesterfield': '0.00', 'birth_city_Chichester': '0.00', 'birth_city_Chigwell': '0.00', 'birth_city_Cinderford': '0.00', 'birth_city_Clevedon': '0.00', 'birth_city_Coalville': '0.00', 'birth_city_Colchester': '0.01', 'birth_city_Consett': '0.00', 'birth_city_Coventry': '0.01', 'birth_city_Cowes': '0.00', 'birth_city_Crawley': '0.00', 'birth_city_Crewe': '0.09', 'birth_city_Crosby': '0.00', 'birth_city_Croydon': '0.05', 'birth_city_Dagenham': '0.00', 'birth_city_Darlington': '0.00', 'birth_city_Dartford': '0.00', 'birth_city_Daventry': '0.00', 'birth_city_Derby': '0.01', 'birth_city_Dewsbury': '0.00', 'birth_city_Doncaster': '0.02', 'birth_city_Dorchester': '0.03', 'birth_city_Douglas [Isle Of Man]': '0.00', 'birth_city_Droylsden': '0.00', 'birth_city_Dublin': '0.00', 'birth_city_Dudley': '0.00', 'birth_city_Durham': '0.03', 'birth_city_Ealing': '0.00', 'birth_city_East Grinstead': '0.00', 'birth_city_Eastbourne': '0.02', 'birth_city_Eastleigh': '0.00', 'birth_city_Edgbaston': '0.00', 'birth_city_Eisenstadt': '0.00', 'birth_city_Enfield': '0.04', 'birth_city_Epsom': '0.00', 'birth_city_Exeter': '0.00', 'birth_city_Exmouth': '0.00', 'birth_city_Farnborough': '0.00', 'birth_city_Felixstowe': '0.00', 'birth_city_Forest Gate': '0.00', 'birth_city_Freetown': '0.00', 'birth_city_Garstang': '0.02', 'birth_city_Gateshead': '0.00', 'birth_city_Gillingham': '0.00', 'birth_city_Gloucester': '0.00', 'birth_city_Goole': '0.00', 'birth_city_Gorleston on Sea': '0.00', 'birth_city_Gosport': '0.00', 'birth_city_Grantham': '0.01', 'birth_city_Gravesend': '0.00', 'birth_city_Great Yarmouth': '0.06', 'birth_city_Grimsby': '0.00', 'birth_city_Guernsey': '0.00', 'birth_city_Guildford': '0.00', 'birth_city_Guisborough': '0.00', 'birth_city_Halesowen': '0.00', 'birth_city_Halifax': '0.00', 'birth_city_Hamilton': '0.00', 'birth_city_Harlow': '0.00', 'birth_city_Harrogate': '0.00', 'birth_city_Harrow': '0.00', 'birth_city_Hartlepool': '0.00', 'birth_city_Hastings': '0.00', 'birth_city_Havant': '0.00', 'birth_city_Haywards Heath': '0.00', 'birth_city_Hebburn': '0.00', 'birth_city_Hednesford': '0.00', 'birth_city_Hemel Hempstead': '0.03', 'birth_city_Hereford': '0.04', 'birth_city_Hexham': '0.12', 'birth_city_High Wycombe': '0.00', 'birth_city_Hillingdon': '0.00', 'birth_city_Hitchin': '0.00', 'birth_city_Hook Norton': '0.00', 'birth_city_Horsham': '0.00', 'birth_city_Hounslow': '0.00', 'birth_city_Huddersfield': '0.02', 'birth_city_Hull': '0.01', 'birth_city_Huntingdon': '0.00', 'birth_city_Huyton': '0.02', 'birth_city_Hyde': '0.00', 'birth_city_Ibadan': '0.00', 'birth_city_Ilford': '0.00', 'birth_city_Ipswich': '0.01', 'birth_city_Isleworth': '0.00', 'birth_city_Jarrow': '0.00', 'birth_city_Jersey': '0.01', 'birth_city_Keighley': '0.00', 'birth_city_Kidderminster': '0.06', 'birth_city_Kidlington': '0.00', \"birth_city_King's Lynn\": '0.00', 'birth_city_Kingston': '0.56', 'birth_city_Kingston upon Thames': '0.00', 'birth_city_Kinshasa': '0.01', 'birth_city_Kuching (Srw)': '0.00', 'birth_city_Kumasi': '0.00', 'birth_city_Lancaster': '0.00', 'birth_city_Leamington Spa': '0.00', 'birth_city_Leeds': '0.04', 'birth_city_Leicester': '0.00', 'birth_city_Leighton Buzzard': '0.00', 'birth_city_Leyton': '0.00', 'birth_city_Lichfield': '0.02', 'birth_city_Lincoln': '0.00', 'birth_city_Lingfield': '0.00', 'birth_city_Liverpool': '0.07', 'birth_city_London': '0.22', 'birth_city_Loughborough': '0.00', 'birth_city_Luanda': '0.00', 'birth_city_Ludlow': '0.00', 'birth_city_Luton': '0.01', 'birth_city_Maidenhead': '0.00', 'birth_city_Maidstone': '0.05', 'birth_city_Manchester': '0.06', 'birth_city_Mansfield': '0.01', 'birth_city_Market Drayton': '0.00', 'birth_city_Market Harborough': '0.00', 'birth_city_Matosinhos': '0.00', 'birth_city_Middlesbrough': '0.28', 'birth_city_Milton Keynes': '0.13', 'birth_city_Montego Bay': '0.00', 'birth_city_Moscow': '0.00', 'birth_city_Nantwich': '0.00', 'birth_city_Newcastle': '0.20', 'birth_city_NewcastleNaNunderNaNLyme': '0.00', 'birth_city_Newport (Isle of Wight)': '0.00', 'birth_city_Newton Aycliffe': '0.32', 'birth_city_North Shields': '0.00', 'birth_city_Northallerton': '0.00', 'birth_city_Northampton': '0.44', 'birth_city_Northfleet': '0.00', 'birth_city_Norwich': '0.00', 'birth_city_Nottingham': '0.01', 'birth_city_Nuneaton': '0.01', 'birth_city_Oakville (ON)': '0.00', 'birth_city_Oldham': '0.00', 'birth_city_Ollerton': '0.03', 'birth_city_Ormskirk': '0.00', 'birth_city_Orpington': '0.00', 'birth_city_Oxford': '0.00', 'birth_city_Paris': '0.00', 'birth_city_Peterborough': '0.00', 'birth_city_Petersfield': '0.00', 'birth_city_Plymouth': '0.00', 'birth_city_Pontefract': '0.00', 'birth_city_Poole': '0.00', 'birth_city_Portsmouth': '0.04', 'birth_city_Preston': '0.03', 'birth_city_Pretoria': '0.00', 'birth_city_Ramsbottom': '0.00', 'birth_city_Reading': '0.41', 'birth_city_Redcar': '0.00', 'birth_city_Redditch': '0.00', 'birth_city_Redhill': '0.00', 'birth_city_Richmond': '0.00', 'birth_city_Ripon': '0.00', 'birth_city_Rochdale': '0.00', 'birth_city_Rochester': '0.00', 'birth_city_Romford': '0.00', 'birth_city_Rotherham': '0.00', 'birth_city_Salford': '0.00', 'birth_city_Salisbury': '0.00', 'birth_city_Scunthorpe': '0.00', 'birth_city_Sedgefield': '0.00', 'birth_city_Selby': '0.00', 'birth_city_Sheffield': '0.00', 'birth_city_Shrewsbury': '0.03', 'birth_city_Sidcup': '0.00', 'birth_city_Slough': '0.23', 'birth_city_Solihull': '0.00', 'birth_city_South Shields': '0.02', 'birth_city_Southampton': '0.00', 'birth_city_SouthendNaNonNaNSea': '0.00', 'birth_city_Southport': '0.00', 'birth_city_Southwark': '0.00', 'birth_city_St. Helens': '0.00', 'birth_city_Stafford': '0.00', 'birth_city_Stalybridge': '0.00', 'birth_city_Stevenage': '0.02', 'birth_city_Stockport': '0.02', 'birth_city_StocktonNaNonNaNTees': '0.10', 'birth_city_StokeNaNonNaNTrent': '0.00', 'birth_city_Stourbridge': '0.09', 'birth_city_Sunderland': '0.02', 'birth_city_Sutton': '0.02', 'birth_city_Sutton Coldfield': '0.00', 'birth_city_Swindon': '0.05', 'birth_city_Tamworth': '0.00', 'birth_city_Taunton': '0.00', 'birth_city_Telford': '0.00', 'birth_city_Thurrock': '0.00', 'birth_city_Tiverton': '0.00', 'birth_city_Torquay': '0.17', 'birth_city_Trowbridge': '0.00', 'birth_city_Truro': '0.00', 'birth_city_Uckfield': '0.00', 'birth_city_Urmston': '0.23', 'birth_city_Vancouver (BC)': '0.00', 'birth_city_Wakefield': '0.00', 'birth_city_Walsall': '0.01', 'birth_city_Walthamstow': '0.00', 'birth_city_Wantage': '0.00', 'birth_city_Warrington': '0.01', 'birth_city_Warwick': '0.00', 'birth_city_Washington': '0.00', 'birth_city_Waterlooville': '0.00', 'birth_city_Watford': '0.00', 'birth_city_Wellingborough': '0.00', 'birth_city_Welwyn Garden City': '0.00', 'birth_city_West Bromwich': '0.00', 'birth_city_Weybridge': '0.00', 'birth_city_Weymouth': '0.00', 'birth_city_Whiston': '0.00', 'birth_city_Whitchurch (Hampshire)': '0.00', 'birth_city_Whitehaven': '0.00', 'birth_city_Whitley Bay': '0.00', 'birth_city_Whitstable': '0.00', 'birth_city_Wigan': '0.05', 'birth_city_Winchester': '0.00', 'birth_city_Winsford': '0.00', 'birth_city_Wisbech': '0.00', 'birth_city_Woking': '0.00', 'birth_city_Wolverhampton': '0.01', 'birth_city_Worthing': '0.01', 'birth_city_Yaound': '0.00', 'birth_city_Yeovil': '0.01', 'birth_city_York': '0.00', 'nation_of_birth_ANG': '0.00', 'nation_of_birth_AUT': '0.00', 'nation_of_birth_BER': '0.00', 'nation_of_birth_CAN': '0.01', 'nation_of_birth_CIV': '0.00', 'nation_of_birth_CMR': '0.00', 'nation_of_birth_COD': '0.04', 'nation_of_birth_ENG': '0.06', 'nation_of_birth_FRA': '0.00', 'nation_of_birth_GHA': '0.00', 'nation_of_birth_GNB': '0.00', 'nation_of_birth_IRL': '0.00', 'nation_of_birth_JAM': '0.61', 'nation_of_birth_MAS': '0.00', 'nation_of_birth_NED': '0.00', 'nation_of_birth_NGA': '0.00', 'nation_of_birth_POR': '0.00', 'nation_of_birth_RSA': '0.00', 'nation_of_birth_RUS': '0.00', 'nation_of_birth_SLE': '0.00', 'birth_region_Caribbean': '0.15', 'birth_region_Central Africa': '0.03', 'birth_region_Central Europe': '0.00', 'birth_region_North America': '0.01', 'birth_region_North Eastern Europe': '0.00', 'birth_region_Southeast Asia': '0.00', 'birth_region_Southern Africa': '0.00', 'birth_region_UK & Ireland': '0.07', 'birth_region_Western Africa': '0.00', 'birth_region_Western Europe': '0.00', 'nationality_ENG': '0.00', 'position_AM (C)': '0.09', 'position_AM (C), ST (C)': '0.01', 'position_AM (L)': '0.02', 'position_AM (L), ST (C)': '0.24', 'position_AM (LC)': '0.04', 'position_AM (LC), ST (C)': '0.01', 'position_AM (R)': '0.05', 'position_AM (R), ST (C)': '0.15', 'position_AM (RC)': '0.04', 'position_AM (RC), ST (C)': '0.01', 'position_AM (RL)': '0.12', 'position_AM (RL), ST (C)': '0.01', 'position_AM (RLC)': '0.05', 'position_AM (RLC), ST (C)': '0.00', 'position_D (C)': '0.01', 'position_D (C), DM': '0.00', 'position_D (C), DM, M (C)': '0.00', 'position_D (L)': '0.00', 'position_D (L), M (C)': '0.00', 'position_D (LC)': '0.01', 'position_D (LC), WB (L)': '0.00', 'position_D (LC), WB/M (L)': '0.00', 'position_D (R)': '0.00', 'position_D (R), DM, M (C)': '0.00', 'position_D (R), M (C)': '0.00', 'position_D (R), WB (RL), DM, M (C)': '0.00', 'position_D (RC)': '0.00', 'position_D (RC), DM': '0.00', 'position_D (RC), WB (R)': '0.00', 'position_D (RL)': '0.00', 'position_D (RL), DM, M (C)': '0.00', 'position_D (RL), WB (L)': '0.00', 'position_D (RL), WB (R)': '0.00', 'position_D (RLC)': '0.00', 'position_D (RLC), WB (RL)': '0.00', 'position_D/M (C)': '0.02', 'position_D/WB (L)': '0.00', 'position_D/WB (L), M (C)': '0.00', 'position_D/WB (R)': '0.00', 'position_D/WB (R), DM': '0.00', 'position_D/WB (R), DM, M (C)': '0.00', 'position_D/WB (R), M (C)': '0.00', 'position_D/WB (RL)': '0.00', 'position_D/WB/M (L)': '0.00', 'position_D/WB/M (R)': '0.00', 'position_D/WB/M/AM (L)': '0.12', 'position_D/WB/M/AM (R)': '0.00', 'position_DM': '0.01', 'position_DM, M (C)': '0.13', 'position_DM, M (RC)': '0.00', 'position_DM, M (RC), AM (R)': '0.00', 'position_DM, M/AM (C)': '0.01', 'position_GK': '0.59', 'position_M (C)': '0.02', 'position_M (C), AM (LC)': '0.02', 'position_M (C), AM (LC), ST (C)': '0.00', 'position_M (C), AM (R)': '0.00', 'position_M (C), AM (RC)': '0.04', 'position_M (C), AM (RLC)': '0.14', 'position_M (L)': '0.00', 'position_M (L), AM (LC)': '0.00', 'position_M (L), AM (RL)': '0.06', 'position_M (L), AM (RLC)': '0.04', 'position_M (LC)': '0.05', 'position_M (LC), AM (L)': '0.00', 'position_M (LC), AM (RLC)': '0.00', 'position_M (R), AM (L)': '0.00', 'position_M (R), AM (RC)': '0.00', 'position_M (R), AM (RL)': '0.01', 'position_M (R), AM (RLC)': '0.01', 'position_M (RC)': '0.00', 'position_M (RC), AM (C)': '0.00', 'position_M (RL), AM (RLC)': '0.04', 'position_M (RLC), AM (C)': '0.00', 'position_M/AM (C)': '0.95', 'position_M/AM (L)': '0.22', 'position_M/AM (R)': '0.39', 'position_M/AM (RL)': '0.09', 'position_ST (C)': '11.30', 'position_WB (L)': '0.00', 'position_WB (L), M (C)': '0.00', 'position_WB (L), M (LC), AM (R)': '0.05', 'position_WB (L), M (RL), AM (C)': '0.00', 'position_WB (R)': '0.00', 'position_WB (R), AM (RC)': '0.02', 'position_WB (R), M (C)': '0.00', 'position_WB (R), M (RC), AM (C)': '0.09', 'position_WB (R), M (RC), AM (R)': '0.00', 'position_WB (R), M/AM (RL)': '0.00', 'position_WB (RL)': '0.03', 'position_WB (RL), M (RC), AM (RL)': '0.00', 'position_WB/AM (L)': '0.00', 'position_WB/AM (R)': '0.01', 'position_WB/M (L)': '0.11', 'position_WB/M (R)': '0.03', 'position_WB/M (RL), AM (R)': '0.00', 'position_WB/M/AM (L)': '0.61', 'position_WB/M/AM (R)': '0.00', 'group_Defender': '0.28', 'group_Forward': '16.08', 'group_Goalkeeper': '0.46', 'group_Midfielder': '4.04', 'club_A. Baleares': '0.00', 'club_AA Gent': '0.00', 'club_AC Milan': '0.00', 'club_AC Oulu': '0.00', 'club_AEL': '0.00', 'club_AFC Croydon Athletic': '0.00', 'club_AFC Fylde': '0.02', 'club_AFC Wimbledon': '0.06', 'club_AS Roma': '0.12', 'club_ASSE': '0.00', 'club_AaB': '0.00', 'club_Aberdeen': '0.00', 'club_Aberystwyth': '0.00', 'club_Accrington': '0.00', 'club_Adelaide United': '0.01', 'club_Ahlen': '0.00', 'club_Airdrieonians': '0.00', 'club_Ajax': '0.00', 'club_Al-Bidda': '0.00', 'club_Al-Entesar Club': '0.00', 'club_Al-Khaleej (KSA)': '0.00', 'club_Al-Qadsiah': '0.00', 'club_Al-Shahaniya': '0.00', 'club_Al-Wakrah': '0.01', 'club_Albacete': '0.00', 'club_Aldershot': '0.22', 'club_Alloa': '0.00', 'club_Altrincham': '0.01', 'club_Amiens SC': '0.00', 'club_Annan Athletic': '0.01', 'club_Arbroath': '0.00', 'club_Aris Limassol': '0.00', 'club_Arsenal': '0.09', 'club_Asker': '0.00', 'club_Aston Villa': '0.18', 'club_Augsburg': '0.00', 'club_Ayr United': '0.11', 'club_Barnet': '0.26', 'club_Barnsley': '0.01', 'club_Barrow': '0.02', 'club_Bath City': '0.00', 'club_Baakehir FK': '0.00', 'club_Beerschot U23': '0.00', 'club_Bellshill': '0.00', 'club_Beikta': '0.00', 'club_Birmingham': '0.00', \"club_Bishop's Stortford\": '0.00', 'club_Blackburn': '0.00', 'club_Blackpool': '0.00', 'club_Blyth': '0.00', 'club_Bohemians': '0.00', 'club_Bolton': '0.00', 'club_Bootle': '0.00', 'club_Boreham Wood': '0.08', 'club_Borussia Dortmund': '0.07', 'club_Bournemouth': '0.01', 'club_Brackley': '0.03', 'club_Bradford City': '0.01', 'club_Braintree': '0.00', 'club_Brentford': '0.48', 'club_Brighton & Hove Albion': '0.00', 'club_Bristol City': '0.02', 'club_Bristol Rovers': '0.01', 'club_Bromley': '0.00', 'club_Brunswick Juventus': '0.00', 'club_Burnley': '0.01', 'club_Burton': '0.01', 'club_Buxton': '0.00', 'club_CC Mariners': '0.00', 'club_Cambridge': '0.01', 'club_Cape Town Spurs': '0.00', 'club_Cardiff': '0.01', 'club_Carlisle': '0.00', 'club_Carolina Core': '0.00', 'club_Castelln': '0.00', 'club_Cavalry FC': '0.00', 'club_Celtic': '0.05', 'club_Charleston': '0.01', 'club_Charlotte FC': '0.00', 'club_Charlton': '0.00', 'club_Chattanooga': '0.03', 'club_Chattanooga FC': '0.01', 'club_Chelsea': '0.18', 'club_Cheltenham': '0.03', 'club_Chennai': '0.00', 'club_Cheshunt': '0.00', 'club_Chesterfield': '0.18', 'club_Chorley': '0.00', 'club_Cliftonville': '0.00', 'club_Club NXT': '0.00', 'club_Colchester': '0.02', 'club_Coldstream': '0.00', 'club_Colorado': '0.00', \"club_Connah's Quay\": '0.00', 'club_Cove Rangers': '0.00', 'club_Coventry': '0.00', 'club_Crawley': '0.03', 'club_Cray': '0.00', 'club_Crewe': '0.02', 'club_Crystal Palace': '0.05', 'club_Dag & Red': '0.00', 'club_Dandenong Thunder': '0.10', 'club_Darlington': '0.00', 'club_Dartford': '0.00', 'club_Derby': '0.07', 'club_Derry City': '0.00', 'club_Detroit City': '0.00', 'club_Doncaster': '0.02', 'club_Dorking': '0.42', 'club_Doxa Katokopias': '0.01', 'club_Drogheda Utd': '0.00', 'club_Dundalk': '0.00', 'club_Dundee': '0.01', 'club_Dundee United': '0.00', 'club_Dunfermline Athletic': '0.00', 'club_East Kilbride': '0.00', 'club_Eastbourne Borough': '0.14', 'club_Eastleigh': '0.05', 'club_Ebbsfleet': '0.05', 'club_Elgin City': '0.00', 'club_Estrela da Amadora B': '0.00', 'club_Everton': '0.09', 'club_Exeter': '0.01', 'club_FC Admira Wacker Mdling': '0.00', 'club_FC Bayern': '0.00', 'club_FC Clifton Hill': '0.00', 'club_FC Halifax': '0.00', 'club_FC Porto': '0.00', 'club_FC United': '0.00', 'club_FC Villefranche': '0.00', 'club_FC Volendam': '0.00', 'club_Falkirk': '0.00', 'club_Farnborough': '0.00', 'club_Fenerbahe': '0.00', 'club_Fleetwood': '0.05', 'club_Forest Green': '0.00', 'club_Fulham': '0.00', 'club_Galway Utd': '0.00', 'club_Gateshead': '0.10', 'club_Genoa': '0.00', 'club_Getafe': '0.00', 'club_Gillingham': '0.04', 'club_Gosport': '0.00', 'club_Greenock Morton': '0.00', 'club_Gretna 2008': '0.00', 'club_Grimsby': '0.00', 'club_Grimsby Boro': '0.00', 'club_Halifax Wanderers FC': '0.03', 'club_Hapoel Acre': '0.00', 'club_Hapoel Petach-Tikva': '0.00', 'club_Harrogate': '0.14', 'club_Hartlepool': '0.01', 'club_Hashtag': '0.00', 'club_Hatayspor': '0.00', 'club_Havant & W': '0.00', 'club_Haverfordwest': '0.00', 'club_Hearts': '0.00', 'club_Heidelberg Utd': '0.00', 'club_Hemel Hempstead': '0.00', 'club_Hertha BSC': '0.00', 'club_Hibernian': '0.00', 'club_Huddersfield': '0.03', 'club_Hull': '0.01', 'club_Hungerford': '0.00', 'club_Huntly': '0.00', 'club_Huntsville': '0.00', 'club_Indy Eleven': '0.00', 'club_Inverness CT': '0.00', 'club_Ipswich': '0.01', 'club_Juventus': '0.00', 'club_KV Kortrijk': '0.00', 'club_Kedah': '0.00', 'club_Kidderminster': '0.00', 'club_Kilmarnock': '0.00', 'club_Kitchee': '0.00', 'club_Knoxville': '0.00', 'club_LOSC': '0.00', 'club_La Castellana': '0.00', 'club_Las Vegas': '0.00', 'club_Lausanne': '0.00', 'club_Leeds': '0.01', 'club_Leicester': '0.01', 'club_Leyton Orient': '0.05', 'club_Lincoln': '0.00', 'club_Linlithgow Rose': '0.00', 'club_Liverpool': '0.00', 'club_Livingston': '0.00', 'club_Loch Ness': '0.00', 'club_Lommel SK': '0.00', 'club_Louisville': '0.00', 'club_Luton': '0.05', 'club_MK Dons': '0.01', 'club_Madison': '0.00', 'club_Magdeburg': '0.00', 'club_Maidenhead': '0.00', 'club_Maidstone': '0.00', 'club_Man City': '0.06', 'club_Manchester United': '0.20', 'club_Mansfield': '0.01', 'club_Marine': '0.00', 'club_Mickleover': '0.12', 'club_Middlesbrough': '0.00', 'club_Millwall': '0.01', 'club_Morecambe': '0.00', 'club_Motherwell': '0.00', 'club_Nairn County': '0.02', 'club_Nashville': '0.00', 'club_New Mexico': '0.00', 'club_Newcastle': '0.04', 'club_Newport Co': '0.15', 'club_Northampton': '0.00', 'club_Northern Colorado': '0.00', 'club_Norwich': '0.00', 'club_Nottm Forest': '0.00', 'club_Notts Co': '0.26', 'club_Nrnberg': '0.00', 'club_OL': '0.00', 'club_Oakleigh Cannons': '0.00', 'club_Oldham': '0.00', 'club_Olympiacos': '0.00', 'club_Omaha': '0.00', 'club_Oostende': '0.00', 'club_Orange County': '0.00', 'club_Orihuela': '0.00', 'club_Oxford City': '0.08', 'club_Oxford United': '0.00', 'club_PAS Giannina': '0.00', 'club_Panserraikos': '0.00', 'club_Partick Thistle': '0.00', 'club_Peterborough': '0.01', 'club_Peterborough Sports': '0.00', 'club_Philadelphia': '0.00', 'club_Phoenix': '0.00', 'club_Phnix Lbeck': '0.00', 'club_Plymouth': '0.00', 'club_Plymouth Parkway': '0.00', 'club_Politehnica Iai': '0.00', 'club_Pollok': '0.00', 'club_Port Vale': '0.00', 'club_Portsmouth': '0.12', 'club_Preston': '0.06', 'club_Preston Athletic': '0.02', 'club_Pusks Akadmia': '0.00', 'club_QPR': '0.00', 'club_Queen of the South': '0.00', \"club_Queen's Park\": '0.00', 'club_R. Madrid': '0.00', 'club_RWD Molenbeek': '0.00', 'club_Rangers': '0.00', 'club_Raufoss': '0.00', 'club_Reading': '0.26', 'club_Real Salt Lake': '0.00', 'club_Richmond': '0.00', 'club_Robina City': '0.00', 'club_Rochdale': '0.01', 'club_Ross County': '0.00', 'club_Rotherham': '0.01', 'club_Royston': '0.00', 'club_SK Austria Klagenfurt': '0.00', 'club_SL16 FC': '0.00', 'club_SV Wehen Wiesbaden': '0.00', 'club_Sacramento': '0.00', 'club_Salford': '0.00', 'club_Sampdoria': '0.00', 'club_Scarborough Athletic': '0.00', 'club_Schalke 04': '0.03', 'club_Scunthorpe': '0.00', 'club_Seattle': '0.00', 'club_Sheff Utd': '0.01', 'club_Sheffield Wednesday': '0.01', 'club_Shelbourne': '0.00', 'club_Sheriff Tiraspol': '0.00', 'club_Shrewsbury': '0.00', 'club_Sligo Rovers': '0.00', 'club_Solihull Moors': '0.02', 'club_Southampton': '0.24', 'club_Southend': '0.03', 'club_Spartans': '0.00', 'club_Spennymoor': '0.00', 'club_Spokane': '0.00', 'club_Sporting CP': '0.00', 'club_St Johnstone': '0.00', 'club_St Mirren': '0.00', 'club_St. Albans': '0.00', 'club_St. Duthus': '0.00', \"club_St. Pat's Athletic\": '0.00', 'club_St. Pauli': '0.01', 'club_Stalybridge': '0.00', 'club_Standard': '0.00', 'club_Stevenage': '0.01', 'club_Stirling': '0.00', 'club_Stirling Uni': '0.00', 'club_Stockport': '0.08', 'club_Stoke': '0.02', 'club_Stourbridge': '0.00', 'club_Stratford': '0.00', 'club_Sunderland': '0.02', 'club_Sutton': '0.02', 'club_Swansea': '0.02', 'club_Swindon': '0.04', 'club_TNS': '0.00', 'club_Talavera': '0.00', 'club_Tampa Bay': '0.00', 'club_Tamworth': '0.01', 'club_Toronto FC II': '0.00', 'club_Torquay': '0.00', 'club_Torremolinos': '0.00', 'club_Tottenham': '0.03', 'club_Totton': '0.00', 'club_Tranmere': '0.02', 'club_Truro': '0.00', 'club_Tulsa': '0.00', 'club_Udinese': '0.00', 'club_Union SG': '0.00', 'club_VAFC': '0.00', 'club_Valour FC': '0.00', 'club_Vancouver 2': '0.13', 'club_Vancouver FC': '0.00', 'club_Vejle': '0.00', 'club_Walsall': '0.30', 'club_Warrington': '0.00', 'club_Warrington Rylands': '0.00', 'club_Waterford': '0.00', 'club_Watford': '0.00', 'club_Wealdstone': '0.00', 'club_Welling': '0.00', 'club_West Brom': '0.07', 'club_West Ham': '0.01', 'club_Weston-super-Mare': '0.00', 'club_Whitley Bay': '0.00', 'club_Wick Acad': '0.00', 'club_Wigan': '0.01', 'club_Woking': '0.11', 'club_Wolves': '0.00', 'club_Worthing': '0.00', 'club_Wrexham': '0.20', 'club_Wycombe': '0.00', 'club_York': '0.26', 'club_stanbulspor': '0.00', 'club_anlurfaspor': '0.00', 'second_nationality_ALB': '0.00', 'second_nationality_ALG': '0.00', 'second_nationality_ANG': '0.00', 'second_nationality_ATG': '0.00', 'second_nationality_AUS': '0.00', 'second_nationality_BAN': '0.00', 'second_nationality_BDI': '0.00', 'second_nationality_BEL': '0.00', 'second_nationality_BER': '0.00', 'second_nationality_BRB': '0.00', 'second_nationality_CAN': '0.01', 'second_nationality_CIV': '0.02', 'second_nationality_CMR': '0.01', 'second_nationality_COD': '0.11', 'second_nationality_COL': '0.00', 'second_nationality_CPV': '0.00', 'second_nationality_CRO': '0.00', 'second_nationality_CYP': '0.00', 'second_nationality_CZE': '0.00', 'second_nationality_DMA': '0.00', 'second_nationality_ECU': '0.00', 'second_nationality_ERI': '0.00', 'second_nationality_ESP': '0.01', 'second_nationality_FRA': '0.00', 'second_nationality_GAM': '0.00', 'second_nationality_GER': '0.00', 'second_nationality_GHA': '0.13', 'second_nationality_GNB': '0.00', 'second_nationality_GRN': '0.00', 'second_nationality_GUI': '0.00', 'second_nationality_GUY': '0.00', 'second_nationality_HKG': '0.00', 'second_nationality_IND': '0.00', 'second_nationality_IRL': '0.06', 'second_nationality_ISR': '0.00', 'second_nationality_ITA': '0.01', 'second_nationality_JAM': '0.35', 'second_nationality_KEN': '0.00', 'second_nationality_LBR': '0.00', 'second_nationality_LCA': '0.00', 'second_nationality_MAR': '0.00', 'second_nationality_MAS': '0.00', 'second_nationality_MLT': '0.00', 'second_nationality_MSR': '0.00', 'second_nationality_NED': '0.01', 'second_nationality_NGA': '0.16', 'second_nationality_NIR': '0.00', 'second_nationality_NOR': '0.00', 'second_nationality_NZL': '0.00', 'second_nationality_PAK': '0.00', 'second_nationality_PHI': '0.00', 'second_nationality_POL': '0.00', 'second_nationality_POR': '0.03', 'second_nationality_RSA': '0.00', 'second_nationality_RUS': '0.00', 'second_nationality_SCO': '0.13', 'second_nationality_SGP': '0.03', 'second_nationality_SKN': '0.00', 'second_nationality_SLE': '0.00', 'second_nationality_TRI': '0.02', 'second_nationality_TUR': '0.00', 'second_nationality_UGA': '0.00', 'second_nationality_USA': '0.18', 'second_nationality_VEN': '0.00', 'second_nationality_WAL': '0.28', 'second_nationality_ZAM': '0.00', 'second_nationality_ZIM': '0.00'}\n",
      "2024-08-14 13:47:32,054 - INFO - Feature importances for appearances (as percentages): {'division': '3.83', 'division_tier': '3.18', 'birth_month': '1.08', 'birth_quarter': '0.50', 'age_(days)_on_1_july_2023': '71.04', 'age_(months)_on_1_july_2023': '8.15', 'age_(years)_on_1_july_2023': '0.23', 'height_(cm)': '1.63', 'weight_(kg)': '2.11', 'is_top_4_tier': '0.74', 'based_in_AUS': '0.02', 'based_in_AUT': '0.00', 'based_in_BEL': '0.00', 'based_in_CAN': '0.00', 'based_in_CYP': '0.00', 'based_in_DEN': '0.00', 'based_in_ECU': '0.00', 'based_in_ENG': '0.34', 'based_in_ESP': '0.02', 'based_in_FIN': '0.04', 'based_in_FRA': '0.00', 'based_in_GER': '0.01', 'based_in_GRE': '0.00', 'based_in_HKG': '0.00', 'based_in_HUN': '0.00', 'based_in_IND': '0.00', 'based_in_IRL': '0.01', 'based_in_ISR': '0.00', 'based_in_ITA': '0.01', 'based_in_KSA': '0.00', 'based_in_MAS': '0.00', 'based_in_MDA': '0.00', 'based_in_NED': '0.00', 'based_in_NIR': '0.00', 'based_in_NOR': '0.00', 'based_in_POR': '0.00', 'based_in_QAT': '0.00', 'based_in_ROU': '0.00', 'based_in_RSA': '0.00', 'based_in_SCO': '0.05', 'based_in_SUI': '0.00', 'based_in_TUR': '0.03', 'based_in_USA': '0.02', 'based_in_WAL': '0.00', 'birth_city_Abidjan': '0.00', 'birth_city_Abingdon': '0.00', 'birth_city_Aldershot': '0.00', 'birth_city_Alsager': '0.00', 'birth_city_Altrincham': '0.00', 'birth_city_Amsterdam': '0.00', 'birth_city_Ascot': '0.00', 'birth_city_Ashford': '0.00', 'birth_city_Ashington': '0.00', 'birth_city_Aylesbury': '0.00', 'birth_city_Bacup': '0.00', 'birth_city_Banbury': '0.00', 'birth_city_Barking': '0.00', 'birth_city_Barnsley': '0.00', 'birth_city_BarrowNaNinNaNFurness': '0.00', 'birth_city_Basildon': '0.00', 'birth_city_Basingstoke': '0.00', 'birth_city_Bath': '0.00', 'birth_city_Bedford': '0.00', 'birth_city_BerwickNaNuponNaNTweed': '0.00', 'birth_city_Beverley': '0.03', 'birth_city_Biddulph': '0.00', 'birth_city_Billingham': '0.00', 'birth_city_Bilston': '0.00', 'birth_city_Birkenhead': '0.00', 'birth_city_Birmingham': '0.02', 'birth_city_Bishop Auckland': '0.00', \"birth_city_Bishop's Stortford\": '0.00', 'birth_city_Bissau': '0.00', 'birth_city_Blackburn': '0.00', 'birth_city_Blackpool': '0.00', 'birth_city_Blyth': '0.00', 'birth_city_Bognor Regis': '0.00', 'birth_city_Bolton': '0.00', 'birth_city_Bootle': '0.00', 'birth_city_Boston': '0.00', 'birth_city_Bournemouth': '0.00', 'birth_city_Bradford': '0.00', 'birth_city_Brentwood': '0.00', 'birth_city_Bridgwater': '0.00', 'birth_city_Bridlington': '0.00', 'birth_city_Brighton': '0.00', 'birth_city_Bristol': '0.00', 'birth_city_Bromley': '0.00', 'birth_city_Bromsgrove': '0.00', 'birth_city_Bunia': '0.00', 'birth_city_Burnley': '0.00', 'birth_city_Burscough': '0.00', 'birth_city_BurtonNaNonNaNTrent': '0.00', 'birth_city_Bury': '0.00', 'birth_city_Bury St. Edmunds': '0.00', 'birth_city_Calgary (AB)': '0.00', 'birth_city_Cambridge': '0.00', 'birth_city_Cannock': '0.00', 'birth_city_Canterbury': '0.00', 'birth_city_Cape Town': '0.00', 'birth_city_Carlisle': '0.00', 'birth_city_Carshalton': '0.00', 'birth_city_Chatham': '0.00', 'birth_city_Chelmsford': '0.00', 'birth_city_Cheltenham': '0.00', 'birth_city_Chertsey': '0.00', 'birth_city_Cheshunt': '0.00', 'birth_city_Chester': '0.00', 'birth_city_ChesterNaNleNaNStreet': '0.00', 'birth_city_Chesterfield': '0.00', 'birth_city_Chichester': '0.00', 'birth_city_Chigwell': '0.00', 'birth_city_Cinderford': '0.00', 'birth_city_Clevedon': '0.00', 'birth_city_Coalville': '0.00', 'birth_city_Colchester': '0.00', 'birth_city_Consett': '0.00', 'birth_city_Coventry': '0.02', 'birth_city_Cowes': '0.00', 'birth_city_Crawley': '0.00', 'birth_city_Crewe': '0.00', 'birth_city_Crosby': '0.00', 'birth_city_Croydon': '0.00', 'birth_city_Dagenham': '0.00', 'birth_city_Darlington': '0.00', 'birth_city_Dartford': '0.00', 'birth_city_Daventry': '0.00', 'birth_city_Derby': '0.05', 'birth_city_Dewsbury': '0.00', 'birth_city_Doncaster': '0.00', 'birth_city_Dorchester': '0.03', 'birth_city_Douglas [Isle Of Man]': '0.00', 'birth_city_Droylsden': '0.00', 'birth_city_Dublin': '0.00', 'birth_city_Dudley': '0.00', 'birth_city_Durham': '0.01', 'birth_city_Ealing': '0.00', 'birth_city_East Grinstead': '0.00', 'birth_city_Eastbourne': '0.00', 'birth_city_Eastleigh': '0.00', 'birth_city_Edgbaston': '0.00', 'birth_city_Eisenstadt': '0.00', 'birth_city_Enfield': '0.00', 'birth_city_Epsom': '0.00', 'birth_city_Exeter': '0.00', 'birth_city_Exmouth': '0.00', 'birth_city_Farnborough': '0.00', 'birth_city_Felixstowe': '0.00', 'birth_city_Forest Gate': '0.00', 'birth_city_Freetown': '0.00', 'birth_city_Garstang': '0.00', 'birth_city_Gateshead': '0.00', 'birth_city_Gillingham': '0.00', 'birth_city_Gloucester': '0.00', 'birth_city_Goole': '0.00', 'birth_city_Gorleston on Sea': '0.00', 'birth_city_Gosport': '0.00', 'birth_city_Grantham': '0.00', 'birth_city_Gravesend': '0.00', 'birth_city_Great Yarmouth': '0.00', 'birth_city_Grimsby': '0.00', 'birth_city_Guernsey': '0.00', 'birth_city_Guildford': '0.00', 'birth_city_Guisborough': '0.00', 'birth_city_Halesowen': '0.00', 'birth_city_Halifax': '0.00', 'birth_city_Hamilton': '0.00', 'birth_city_Harlow': '0.00', 'birth_city_Harrogate': '0.00', 'birth_city_Harrow': '0.00', 'birth_city_Hartlepool': '0.00', 'birth_city_Hastings': '0.00', 'birth_city_Havant': '0.00', 'birth_city_Haywards Heath': '0.00', 'birth_city_Hebburn': '0.00', 'birth_city_Hednesford': '0.00', 'birth_city_Hemel Hempstead': '0.00', 'birth_city_Hereford': '0.00', 'birth_city_Hexham': '0.00', 'birth_city_High Wycombe': '0.00', 'birth_city_Hillingdon': '0.00', 'birth_city_Hitchin': '0.00', 'birth_city_Hook Norton': '0.00', 'birth_city_Horsham': '0.00', 'birth_city_Hounslow': '0.00', 'birth_city_Huddersfield': '0.00', 'birth_city_Hull': '0.01', 'birth_city_Huntingdon': '0.00', 'birth_city_Huyton': '0.01', 'birth_city_Hyde': '0.00', 'birth_city_Ibadan': '0.00', 'birth_city_Ilford': '0.00', 'birth_city_Ipswich': '0.00', 'birth_city_Isleworth': '0.00', 'birth_city_Jarrow': '0.00', 'birth_city_Jersey': '0.00', 'birth_city_Keighley': '0.00', 'birth_city_Kidderminster': '0.00', 'birth_city_Kidlington': '0.00', \"birth_city_King's Lynn\": '0.00', 'birth_city_Kingston': '0.00', 'birth_city_Kingston upon Thames': '0.00', 'birth_city_Kinshasa': '0.00', 'birth_city_Kuching (Srw)': '0.00', 'birth_city_Kumasi': '0.00', 'birth_city_Lancaster': '0.00', 'birth_city_Leamington Spa': '0.00', 'birth_city_Leeds': '0.03', 'birth_city_Leicester': '0.01', 'birth_city_Leighton Buzzard': '0.00', 'birth_city_Leyton': '0.00', 'birth_city_Lichfield': '0.00', 'birth_city_Lincoln': '0.00', 'birth_city_Lingfield': '0.00', 'birth_city_Liverpool': '0.04', 'birth_city_London': '0.27', 'birth_city_Loughborough': '0.00', 'birth_city_Luanda': '0.00', 'birth_city_Ludlow': '0.00', 'birth_city_Luton': '0.00', 'birth_city_Maidenhead': '0.00', 'birth_city_Maidstone': '0.00', 'birth_city_Manchester': '0.13', 'birth_city_Mansfield': '0.00', 'birth_city_Market Drayton': '0.00', 'birth_city_Market Harborough': '0.00', 'birth_city_Matosinhos': '0.00', 'birth_city_Middlesbrough': '0.01', 'birth_city_Milton Keynes': '0.00', 'birth_city_Montego Bay': '0.00', 'birth_city_Moscow': '0.00', 'birth_city_Nantwich': '0.00', 'birth_city_Newcastle': '0.02', 'birth_city_NewcastleNaNunderNaNLyme': '0.00', 'birth_city_Newport (Isle of Wight)': '0.00', 'birth_city_Newton Aycliffe': '0.00', 'birth_city_North Shields': '0.00', 'birth_city_Northallerton': '0.00', 'birth_city_Northampton': '0.00', 'birth_city_Northfleet': '0.00', 'birth_city_Norwich': '0.00', 'birth_city_Nottingham': '0.02', 'birth_city_Nuneaton': '0.00', 'birth_city_Oakville (ON)': '0.00', 'birth_city_Oldham': '0.00', 'birth_city_Ollerton': '0.00', 'birth_city_Ormskirk': '0.00', 'birth_city_Orpington': '0.00', 'birth_city_Oxford': '0.00', 'birth_city_Paris': '0.00', 'birth_city_Peterborough': '0.00', 'birth_city_Petersfield': '0.00', 'birth_city_Plymouth': '0.00', 'birth_city_Pontefract': '0.00', 'birth_city_Poole': '0.00', 'birth_city_Portsmouth': '0.00', 'birth_city_Preston': '0.00', 'birth_city_Pretoria': '0.00', 'birth_city_Ramsbottom': '0.00', 'birth_city_Reading': '0.00', 'birth_city_Redcar': '0.00', 'birth_city_Redditch': '0.00', 'birth_city_Redhill': '0.00', 'birth_city_Richmond': '0.00', 'birth_city_Ripon': '0.00', 'birth_city_Rochdale': '0.00', 'birth_city_Rochester': '0.00', 'birth_city_Romford': '0.00', 'birth_city_Rotherham': '0.00', 'birth_city_Salford': '0.00', 'birth_city_Salisbury': '0.00', 'birth_city_Scunthorpe': '0.00', 'birth_city_Sedgefield': '0.00', 'birth_city_Selby': '0.00', 'birth_city_Sheffield': '0.00', 'birth_city_Shrewsbury': '0.00', 'birth_city_Sidcup': '0.00', 'birth_city_Slough': '0.00', 'birth_city_Solihull': '0.01', 'birth_city_South Shields': '0.00', 'birth_city_Southampton': '0.00', 'birth_city_SouthendNaNonNaNSea': '0.00', 'birth_city_Southport': '0.00', 'birth_city_Southwark': '0.00', 'birth_city_St. Helens': '0.00', 'birth_city_Stafford': '0.00', 'birth_city_Stalybridge': '0.00', 'birth_city_Stevenage': '0.00', 'birth_city_Stockport': '0.00', 'birth_city_StocktonNaNonNaNTees': '0.00', 'birth_city_StokeNaNonNaNTrent': '0.00', 'birth_city_Stourbridge': '0.00', 'birth_city_Sunderland': '0.00', 'birth_city_Sutton': '0.00', 'birth_city_Sutton Coldfield': '0.00', 'birth_city_Swindon': '0.00', 'birth_city_Tamworth': '0.00', 'birth_city_Taunton': '0.00', 'birth_city_Telford': '0.00', 'birth_city_Thurrock': '0.00', 'birth_city_Tiverton': '0.00', 'birth_city_Torquay': '0.01', 'birth_city_Trowbridge': '0.00', 'birth_city_Truro': '0.00', 'birth_city_Uckfield': '0.00', 'birth_city_Urmston': '0.00', 'birth_city_Vancouver (BC)': '0.00', 'birth_city_Wakefield': '0.00', 'birth_city_Walsall': '0.00', 'birth_city_Walthamstow': '0.00', 'birth_city_Wantage': '0.00', 'birth_city_Warrington': '0.00', 'birth_city_Warwick': '0.00', 'birth_city_Washington': '0.00', 'birth_city_Waterlooville': '0.00', 'birth_city_Watford': '0.00', 'birth_city_Wellingborough': '0.00', 'birth_city_Welwyn Garden City': '0.00', 'birth_city_West Bromwich': '0.00', 'birth_city_Weybridge': '0.00', 'birth_city_Weymouth': '0.00', 'birth_city_Whiston': '0.00', 'birth_city_Whitchurch (Hampshire)': '0.00', 'birth_city_Whitehaven': '0.00', 'birth_city_Whitley Bay': '0.00', 'birth_city_Whitstable': '0.00', 'birth_city_Wigan': '0.00', 'birth_city_Winchester': '0.00', 'birth_city_Winsford': '0.00', 'birth_city_Wisbech': '0.00', 'birth_city_Woking': '0.00', 'birth_city_Wolverhampton': '0.00', 'birth_city_Worthing': '0.00', 'birth_city_Yaound': '0.00', 'birth_city_Yeovil': '0.00', 'birth_city_York': '0.00', 'nation_of_birth_ANG': '0.00', 'nation_of_birth_AUT': '0.00', 'nation_of_birth_BER': '0.00', 'nation_of_birth_CAN': '0.00', 'nation_of_birth_CIV': '0.00', 'nation_of_birth_CMR': '0.00', 'nation_of_birth_COD': '0.00', 'nation_of_birth_ENG': '0.01', 'nation_of_birth_FRA': '0.00', 'nation_of_birth_GHA': '0.00', 'nation_of_birth_GNB': '0.00', 'nation_of_birth_IRL': '0.00', 'nation_of_birth_JAM': '0.00', 'nation_of_birth_MAS': '0.00', 'nation_of_birth_NED': '0.00', 'nation_of_birth_NGA': '0.00', 'nation_of_birth_POR': '0.00', 'nation_of_birth_RSA': '0.00', 'nation_of_birth_RUS': '0.00', 'nation_of_birth_SLE': '0.00', 'birth_region_Caribbean': '0.00', 'birth_region_Central Africa': '0.00', 'birth_region_Central Europe': '0.00', 'birth_region_North America': '0.00', 'birth_region_North Eastern Europe': '0.00', 'birth_region_Southeast Asia': '0.00', 'birth_region_Southern Africa': '0.00', 'birth_region_UK & Ireland': '0.01', 'birth_region_Western Africa': '0.00', 'birth_region_Western Europe': '0.00', 'nationality_ENG': '0.00', 'position_AM (C)': '0.02', 'position_AM (C), ST (C)': '0.00', 'position_AM (L)': '0.01', 'position_AM (L), ST (C)': '0.05', 'position_AM (LC)': '0.00', 'position_AM (LC), ST (C)': '0.00', 'position_AM (R)': '0.02', 'position_AM (R), ST (C)': '0.05', 'position_AM (RC)': '0.03', 'position_AM (RC), ST (C)': '0.00', 'position_AM (RL)': '0.10', 'position_AM (RL), ST (C)': '0.00', 'position_AM (RLC)': '0.02', 'position_AM (RLC), ST (C)': '0.00', 'position_D (C)': '0.28', 'position_D (C), DM': '0.00', 'position_D (C), DM, M (C)': '0.00', 'position_D (L)': '0.07', 'position_D (L), M (C)': '0.00', 'position_D (LC)': '0.04', 'position_D (LC), WB (L)': '0.00', 'position_D (LC), WB/M (L)': '0.00', 'position_D (R)': '0.05', 'position_D (R), DM, M (C)': '0.00', 'position_D (R), M (C)': '0.00', 'position_D (R), WB (RL), DM, M (C)': '0.00', 'position_D (RC)': '0.04', 'position_D (RC), DM': '0.00', 'position_D (RC), WB (R)': '0.00', 'position_D (RL)': '0.00', 'position_D (RL), DM, M (C)': '0.00', 'position_D (RL), WB (L)': '0.00', 'position_D (RL), WB (R)': '0.00', 'position_D (RLC)': '0.00', 'position_D (RLC), WB (RL)': '0.00', 'position_D/M (C)': '0.00', 'position_D/WB (L)': '0.08', 'position_D/WB (L), M (C)': '0.00', 'position_D/WB (R)': '0.15', 'position_D/WB (R), DM': '0.00', 'position_D/WB (R), DM, M (C)': '0.00', 'position_D/WB (R), M (C)': '0.00', 'position_D/WB (RL)': '0.00', 'position_D/WB/M (L)': '0.00', 'position_D/WB/M (R)': '0.00', 'position_D/WB/M/AM (L)': '0.02', 'position_D/WB/M/AM (R)': '0.00', 'position_DM': '0.04', 'position_DM, M (C)': '0.08', 'position_DM, M (RC)': '0.00', 'position_DM, M (RC), AM (R)': '0.00', 'position_DM, M/AM (C)': '0.00', 'position_GK': '0.61', 'position_M (C)': '0.26', 'position_M (C), AM (LC)': '0.00', 'position_M (C), AM (LC), ST (C)': '0.00', 'position_M (C), AM (R)': '0.00', 'position_M (C), AM (RC)': '0.00', 'position_M (C), AM (RLC)': '0.00', 'position_M (L)': '0.00', 'position_M (L), AM (LC)': '0.00', 'position_M (L), AM (RL)': '0.00', 'position_M (L), AM (RLC)': '0.00', 'position_M (LC)': '0.00', 'position_M (LC), AM (L)': '0.00', 'position_M (LC), AM (RLC)': '0.00', 'position_M (R), AM (L)': '0.00', 'position_M (R), AM (RC)': '0.00', 'position_M (R), AM (RL)': '0.00', 'position_M (R), AM (RLC)': '0.00', 'position_M (RC)': '0.00', 'position_M (RC), AM (C)': '0.00', 'position_M (RL), AM (RLC)': '0.00', 'position_M (RLC), AM (C)': '0.00', 'position_M/AM (C)': '0.02', 'position_M/AM (L)': '0.00', 'position_M/AM (R)': '0.20', 'position_M/AM (RL)': '0.01', 'position_ST (C)': '0.24', 'position_WB (L)': '0.00', 'position_WB (L), M (C)': '0.00', 'position_WB (L), M (LC), AM (R)': '0.00', 'position_WB (L), M (RL), AM (C)': '0.00', 'position_WB (R)': '0.00', 'position_WB (R), AM (RC)': '0.00', 'position_WB (R), M (C)': '0.00', 'position_WB (R), M (RC), AM (C)': '0.00', 'position_WB (R), M (RC), AM (R)': '0.00', 'position_WB (R), M/AM (RL)': '0.00', 'position_WB (RL)': '0.00', 'position_WB (RL), M (RC), AM (RL)': '0.00', 'position_WB/AM (L)': '0.00', 'position_WB/AM (R)': '0.00', 'position_WB/M (L)': '0.00', 'position_WB/M (R)': '0.00', 'position_WB/M (RL), AM (R)': '0.00', 'position_WB/M/AM (L)': '0.00', 'position_WB/M/AM (R)': '0.00', 'group_Defender': '0.34', 'group_Forward': '0.38', 'group_Goalkeeper': '0.96', 'group_Midfielder': '0.23', 'club_A. Baleares': '0.00', 'club_AA Gent': '0.00', 'club_AC Milan': '0.00', 'club_AC Oulu': '0.00', 'club_AEL': '0.00', 'club_AFC Croydon Athletic': '0.00', 'club_AFC Fylde': '0.01', 'club_AFC Wimbledon': '0.02', 'club_AS Roma': '0.00', 'club_ASSE': '0.00', 'club_AaB': '0.00', 'club_Aberdeen': '0.00', 'club_Aberystwyth': '0.00', 'club_Accrington': '0.00', 'club_Adelaide United': '0.00', 'club_Ahlen': '0.00', 'club_Airdrieonians': '0.00', 'club_Ajax': '0.00', 'club_Al-Bidda': '0.00', 'club_Al-Entesar Club': '0.00', 'club_Al-Khaleej (KSA)': '0.00', 'club_Al-Qadsiah': '0.00', 'club_Al-Shahaniya': '0.00', 'club_Al-Wakrah': '0.00', 'club_Albacete': '0.00', 'club_Aldershot': '0.02', 'club_Alloa': '0.00', 'club_Altrincham': '0.01', 'club_Amiens SC': '0.00', 'club_Annan Athletic': '0.00', 'club_Arbroath': '0.00', 'club_Aris Limassol': '0.00', 'club_Arsenal': '0.00', 'club_Asker': '0.00', 'club_Aston Villa': '0.01', 'club_Augsburg': '0.00', 'club_Ayr United': '0.00', 'club_Barnet': '0.00', 'club_Barnsley': '0.01', 'club_Barrow': '0.00', 'club_Bath City': '0.00', 'club_Baakehir FK': '0.00', 'club_Beerschot U23': '0.00', 'club_Bellshill': '0.00', 'club_Beikta': '0.00', 'club_Birmingham': '0.00', \"club_Bishop's Stortford\": '0.00', 'club_Blackburn': '0.01', 'club_Blackpool': '0.02', 'club_Blyth': '0.00', 'club_Bohemians': '0.01', 'club_Bolton': '0.00', 'club_Bootle': '0.00', 'club_Boreham Wood': '0.00', 'club_Borussia Dortmund': '0.00', 'club_Bournemouth': '0.01', 'club_Brackley': '0.00', 'club_Bradford City': '0.05', 'club_Braintree': '0.00', 'club_Brentford': '0.00', 'club_Brighton & Hove Albion': '0.00', 'club_Bristol City': '0.01', 'club_Bristol Rovers': '0.00', 'club_Bromley': '0.00', 'club_Brunswick Juventus': '0.00', 'club_Burnley': '0.01', 'club_Burton': '0.01', 'club_Buxton': '0.00', 'club_CC Mariners': '0.00', 'club_Cambridge': '0.00', 'club_Cape Town Spurs': '0.00', 'club_Cardiff': '0.02', 'club_Carlisle': '0.02', 'club_Carolina Core': '0.00', 'club_Castelln': '0.00', 'club_Cavalry FC': '0.00', 'club_Celtic': '0.00', 'club_Charleston': '0.00', 'club_Charlotte FC': '0.00', 'club_Charlton': '0.01', 'club_Chattanooga': '0.00', 'club_Chattanooga FC': '0.00', 'club_Chelsea': '0.00', 'club_Cheltenham': '0.00', 'club_Chennai': '0.00', 'club_Cheshunt': '0.00', 'club_Chesterfield': '0.01', 'club_Chorley': '0.00', 'club_Cliftonville': '0.00', 'club_Club NXT': '0.00', 'club_Colchester': '0.01', 'club_Coldstream': '0.00', 'club_Colorado': '0.00', \"club_Connah's Quay\": '0.00', 'club_Cove Rangers': '0.00', 'club_Coventry': '0.00', 'club_Crawley': '0.01', 'club_Cray': '0.00', 'club_Crewe': '0.01', 'club_Crystal Palace': '0.00', 'club_Dag & Red': '0.03', 'club_Dandenong Thunder': '0.00', 'club_Darlington': '0.00', 'club_Dartford': '0.00', 'club_Derby': '0.11', 'club_Derry City': '0.00', 'club_Detroit City': '0.00', 'club_Doncaster': '0.00', 'club_Dorking': '0.01', 'club_Doxa Katokopias': '0.00', 'club_Drogheda Utd': '0.00', 'club_Dundalk': '0.00', 'club_Dundee': '0.00', 'club_Dundee United': '0.00', 'club_Dunfermline Athletic': '0.00', 'club_East Kilbride': '0.00', 'club_Eastbourne Borough': '0.00', 'club_Eastleigh': '0.00', 'club_Ebbsfleet': '0.00', 'club_Elgin City': '0.01', 'club_Estrela da Amadora B': '0.00', 'club_Everton': '0.00', 'club_Exeter': '0.00', 'club_FC Admira Wacker Mdling': '0.00', 'club_FC Bayern': '0.00', 'club_FC Clifton Hill': '0.00', 'club_FC Halifax': '0.01', 'club_FC Porto': '0.00', 'club_FC United': '0.00', 'club_FC Villefranche': '0.00', 'club_FC Volendam': '0.00', 'club_Falkirk': '0.00', 'club_Farnborough': '0.00', 'club_Fenerbahe': '0.00', 'club_Fleetwood': '0.00', 'club_Forest Green': '0.01', 'club_Fulham': '0.00', 'club_Galway Utd': '0.00', 'club_Gateshead': '0.00', 'club_Genoa': '0.00', 'club_Getafe': '0.00', 'club_Gillingham': '0.01', 'club_Gosport': '0.00', 'club_Greenock Morton': '0.00', 'club_Gretna 2008': '0.00', 'club_Grimsby': '0.01', 'club_Grimsby Boro': '0.00', 'club_Halifax Wanderers FC': '0.00', 'club_Hapoel Acre': '0.00', 'club_Hapoel Petach-Tikva': '0.00', 'club_Harrogate': '0.01', 'club_Hartlepool': '0.01', 'club_Hashtag': '0.00', 'club_Hatayspor': '0.00', 'club_Havant & W': '0.00', 'club_Haverfordwest': '0.00', 'club_Hearts': '0.01', 'club_Heidelberg Utd': '0.00', 'club_Hemel Hempstead': '0.00', 'club_Hertha BSC': '0.00', 'club_Hibernian': '0.00', 'club_Huddersfield': '0.01', 'club_Hull': '0.00', 'club_Hungerford': '0.00', 'club_Huntly': '0.00', 'club_Huntsville': '0.00', 'club_Indy Eleven': '0.00', 'club_Inverness CT': '0.00', 'club_Ipswich': '0.01', 'club_Juventus': '0.00', 'club_KV Kortrijk': '0.00', 'club_Kedah': '0.00', 'club_Kidderminster': '0.00', 'club_Kilmarnock': '0.00', 'club_Kitchee': '0.00', 'club_Knoxville': '0.00', 'club_LOSC': '0.00', 'club_La Castellana': '0.00', 'club_Las Vegas': '0.00', 'club_Lausanne': '0.00', 'club_Leeds': '0.01', 'club_Leicester': '0.00', 'club_Leyton Orient': '0.00', 'club_Lincoln': '0.00', 'club_Linlithgow Rose': '0.00', 'club_Liverpool': '0.00', 'club_Livingston': '0.00', 'club_Loch Ness': '0.00', 'club_Lommel SK': '0.00', 'club_Louisville': '0.00', 'club_Luton': '0.01', 'club_MK Dons': '0.07', 'club_Madison': '0.00', 'club_Magdeburg': '0.00', 'club_Maidenhead': '0.01', 'club_Maidstone': '0.00', 'club_Man City': '0.00', 'club_Manchester United': '0.00', 'club_Mansfield': '0.01', 'club_Marine': '0.00', 'club_Mickleover': '0.00', 'club_Middlesbrough': '0.00', 'club_Millwall': '0.01', 'club_Morecambe': '0.02', 'club_Motherwell': '0.00', 'club_Nairn County': '0.00', 'club_Nashville': '0.01', 'club_New Mexico': '0.00', 'club_Newcastle': '0.00', 'club_Newport Co': '0.00', 'club_Northampton': '0.01', 'club_Northern Colorado': '0.00', 'club_Norwich': '0.00', 'club_Nottm Forest': '0.00', 'club_Notts Co': '0.00', 'club_Nrnberg': '0.00', 'club_OL': '0.00', 'club_Oakleigh Cannons': '0.00', 'club_Oldham': '0.00', 'club_Olympiacos': '0.00', 'club_Omaha': '0.00', 'club_Oostende': '0.00', 'club_Orange County': '0.00', 'club_Orihuela': '0.00', 'club_Oxford City': '0.01', 'club_Oxford United': '0.01', 'club_PAS Giannina': '0.00', 'club_Panserraikos': '0.00', 'club_Partick Thistle': '0.00', 'club_Peterborough': '0.05', 'club_Peterborough Sports': '0.00', 'club_Philadelphia': '0.00', 'club_Phoenix': '0.00', 'club_Phnix Lbeck': '0.00', 'club_Plymouth': '0.00', 'club_Plymouth Parkway': '0.00', 'club_Politehnica Iai': '0.00', 'club_Pollok': '0.00', 'club_Port Vale': '0.01', 'club_Portsmouth': '0.03', 'club_Preston': '0.01', 'club_Preston Athletic': '0.00', 'club_Pusks Akadmia': '0.00', 'club_QPR': '0.00', 'club_Queen of the South': '0.00', \"club_Queen's Park\": '0.00', 'club_R. Madrid': '0.00', 'club_RWD Molenbeek': '0.00', 'club_Rangers': '0.00', 'club_Raufoss': '0.00', 'club_Reading': '0.00', 'club_Real Salt Lake': '0.00', 'club_Richmond': '0.00', 'club_Robina City': '0.00', 'club_Rochdale': '0.00', 'club_Ross County': '0.00', 'club_Rotherham': '0.00', 'club_Royston': '0.00', 'club_SK Austria Klagenfurt': '0.00', 'club_SL16 FC': '0.00', 'club_SV Wehen Wiesbaden': '0.00', 'club_Sacramento': '0.00', 'club_Salford': '0.04', 'club_Sampdoria': '0.00', 'club_Scarborough Athletic': '0.00', 'club_Schalke 04': '0.00', 'club_Scunthorpe': '0.00', 'club_Seattle': '0.00', 'club_Sheff Utd': '0.00', 'club_Sheffield Wednesday': '0.00', 'club_Shelbourne': '0.00', 'club_Sheriff Tiraspol': '0.00', 'club_Shrewsbury': '0.00', 'club_Sligo Rovers': '0.00', 'club_Solihull Moors': '0.01', 'club_Southampton': '0.08', 'club_Southend': '0.02', 'club_Spartans': '0.00', 'club_Spennymoor': '0.00', 'club_Spokane': '0.00', 'club_Sporting CP': '0.00', 'club_St Johnstone': '0.00', 'club_St Mirren': '0.00', 'club_St. Albans': '0.00', 'club_St. Duthus': '0.00', \"club_St. Pat's Athletic\": '0.00', 'club_St. Pauli': '0.00', 'club_Stalybridge': '0.00', 'club_Standard': '0.00', 'club_Stevenage': '0.03', 'club_Stirling': '0.00', 'club_Stirling Uni': '0.00', 'club_Stockport': '0.07', 'club_Stoke': '0.00', 'club_Stourbridge': '0.00', 'club_Stratford': '0.00', 'club_Sunderland': '0.00', 'club_Sutton': '0.01', 'club_Swansea': '0.01', 'club_Swindon': '0.00', 'club_TNS': '0.00', 'club_Talavera': '0.00', 'club_Tampa Bay': '0.00', 'club_Tamworth': '0.00', 'club_Toronto FC II': '0.00', 'club_Torquay': '0.00', 'club_Torremolinos': '0.00', 'club_Tottenham': '0.01', 'club_Totton': '0.00', 'club_Tranmere': '0.03', 'club_Truro': '0.00', 'club_Tulsa': '0.00', 'club_Udinese': '0.00', 'club_Union SG': '0.00', 'club_VAFC': '0.00', 'club_Valour FC': '0.00', 'club_Vancouver 2': '0.00', 'club_Vancouver FC': '0.00', 'club_Vejle': '0.00', 'club_Walsall': '0.01', 'club_Warrington': '0.00', 'club_Warrington Rylands': '0.00', 'club_Waterford': '0.00', 'club_Watford': '0.00', 'club_Wealdstone': '0.02', 'club_Welling': '0.00', 'club_West Brom': '0.12', 'club_West Ham': '0.00', 'club_Weston-super-Mare': '0.00', 'club_Whitley Bay': '0.00', 'club_Wick Acad': '0.00', 'club_Wigan': '0.00', 'club_Woking': '0.00', 'club_Wolves': '0.00', 'club_Worthing': '0.00', 'club_Wrexham': '0.00', 'club_Wycombe': '0.00', 'club_York': '0.02', 'club_stanbulspor': '0.00', 'club_anlurfaspor': '0.00', 'second_nationality_ALB': '0.00', 'second_nationality_ALG': '0.00', 'second_nationality_ANG': '0.00', 'second_nationality_ATG': '0.00', 'second_nationality_AUS': '0.00', 'second_nationality_BAN': '0.00', 'second_nationality_BDI': '0.00', 'second_nationality_BEL': '0.00', 'second_nationality_BER': '0.00', 'second_nationality_BRB': '0.01', 'second_nationality_CAN': '0.00', 'second_nationality_CIV': '0.00', 'second_nationality_CMR': '0.00', 'second_nationality_COD': '0.02', 'second_nationality_COL': '0.00', 'second_nationality_CPV': '0.00', 'second_nationality_CRO': '0.00', 'second_nationality_CYP': '0.00', 'second_nationality_CZE': '0.00', 'second_nationality_DMA': '0.00', 'second_nationality_ECU': '0.00', 'second_nationality_ERI': '0.00', 'second_nationality_ESP': '0.00', 'second_nationality_FRA': '0.00', 'second_nationality_GAM': '0.00', 'second_nationality_GER': '0.00', 'second_nationality_GHA': '0.00', 'second_nationality_GNB': '0.00', 'second_nationality_GRN': '0.00', 'second_nationality_GUI': '0.00', 'second_nationality_GUY': '0.00', 'second_nationality_HKG': '0.00', 'second_nationality_IND': '0.00', 'second_nationality_IRL': '0.01', 'second_nationality_ISR': '0.00', 'second_nationality_ITA': '0.00', 'second_nationality_JAM': '0.08', 'second_nationality_KEN': '0.00', 'second_nationality_LBR': '0.00', 'second_nationality_LCA': '0.00', 'second_nationality_MAR': '0.00', 'second_nationality_MAS': '0.00', 'second_nationality_MLT': '0.00', 'second_nationality_MSR': '0.00', 'second_nationality_NED': '0.00', 'second_nationality_NGA': '0.07', 'second_nationality_NIR': '0.00', 'second_nationality_NOR': '0.00', 'second_nationality_NZL': '0.00', 'second_nationality_PAK': '0.00', 'second_nationality_PHI': '0.00', 'second_nationality_POL': '0.00', 'second_nationality_POR': '0.00', 'second_nationality_RSA': '0.00', 'second_nationality_RUS': '0.00', 'second_nationality_SCO': '0.03', 'second_nationality_SGP': '0.00', 'second_nationality_SKN': '0.00', 'second_nationality_SLE': '0.00', 'second_nationality_TRI': '0.00', 'second_nationality_TUR': '0.00', 'second_nationality_UGA': '0.00', 'second_nationality_USA': '0.13', 'second_nationality_VEN': '0.00', 'second_nationality_WAL': '0.01', 'second_nationality_ZAM': '0.00', 'second_nationality_ZIM': '0.00'}\n",
      "2024-08-14 13:47:32,055 - INFO - Feature importances for tier quality (as percentages): {'division': '13.01', 'division_tier': '16.97', 'birth_month': '0.15', 'birth_quarter': '0.11', 'age_(days)_on_1_july_2023': '0.30', 'age_(months)_on_1_july_2023': '0.24', 'age_(years)_on_1_july_2023': '0.18', 'height_(cm)': '0.19', 'weight_(kg)': '0.18', 'is_top_4_tier': '15.44', 'based_in_AUS': '0.03', 'based_in_AUT': '0.02', 'based_in_BEL': '0.02', 'based_in_CAN': '0.01', 'based_in_CYP': '0.05', 'based_in_DEN': '0.01', 'based_in_ECU': '0.00', 'based_in_ENG': '4.17', 'based_in_ESP': '0.01', 'based_in_FIN': '0.03', 'based_in_FRA': '0.01', 'based_in_GER': '0.10', 'based_in_GRE': '0.08', 'based_in_HKG': '0.00', 'based_in_HUN': '0.00', 'based_in_IND': '0.00', 'based_in_IRL': '0.21', 'based_in_ISR': '0.00', 'based_in_ITA': '0.26', 'based_in_KSA': '0.00', 'based_in_MAS': '0.00', 'based_in_MDA': '0.01', 'based_in_NED': '0.03', 'based_in_NIR': '0.00', 'based_in_NOR': '0.01', 'based_in_POR': '0.01', 'based_in_QAT': '0.00', 'based_in_ROU': '0.00', 'based_in_RSA': '0.00', 'based_in_SCO': '2.04', 'based_in_SUI': '0.00', 'based_in_TUR': '0.03', 'based_in_USA': '0.18', 'based_in_WAL': '0.01', 'birth_city_Abidjan': '0.00', 'birth_city_Abingdon': '0.00', 'birth_city_Aldershot': '0.00', 'birth_city_Alsager': '0.00', 'birth_city_Altrincham': '0.00', 'birth_city_Amsterdam': '0.00', 'birth_city_Ascot': '0.00', 'birth_city_Ashford': '0.00', 'birth_city_Ashington': '0.01', 'birth_city_Aylesbury': '0.00', 'birth_city_Bacup': '0.00', 'birth_city_Banbury': '0.00', 'birth_city_Barking': '0.00', 'birth_city_Barnsley': '0.00', 'birth_city_BarrowNaNinNaNFurness': '0.00', 'birth_city_Basildon': '0.00', 'birth_city_Basingstoke': '0.00', 'birth_city_Bath': '0.00', 'birth_city_Bedford': '0.01', 'birth_city_BerwickNaNuponNaNTweed': '0.00', 'birth_city_Beverley': '0.00', 'birth_city_Biddulph': '0.00', 'birth_city_Billingham': '0.00', 'birth_city_Bilston': '0.00', 'birth_city_Birkenhead': '0.00', 'birth_city_Birmingham': '0.01', 'birth_city_Bishop Auckland': '0.03', \"birth_city_Bishop's Stortford\": '0.00', 'birth_city_Bissau': '0.00', 'birth_city_Blackburn': '0.01', 'birth_city_Blackpool': '0.00', 'birth_city_Blyth': '0.00', 'birth_city_Bognor Regis': '0.00', 'birth_city_Bolton': '0.00', 'birth_city_Bootle': '0.00', 'birth_city_Boston': '0.00', 'birth_city_Bournemouth': '0.00', 'birth_city_Bradford': '0.02', 'birth_city_Brentwood': '0.00', 'birth_city_Bridgwater': '0.00', 'birth_city_Bridlington': '0.00', 'birth_city_Brighton': '0.04', 'birth_city_Bristol': '0.02', 'birth_city_Bromley': '0.00', 'birth_city_Bromsgrove': '0.00', 'birth_city_Bunia': '0.00', 'birth_city_Burnley': '0.00', 'birth_city_Burscough': '0.01', 'birth_city_BurtonNaNonNaNTrent': '0.00', 'birth_city_Bury': '0.00', 'birth_city_Bury St. Edmunds': '0.00', 'birth_city_Calgary (AB)': '0.00', 'birth_city_Cambridge': '0.04', 'birth_city_Cannock': '0.00', 'birth_city_Canterbury': '0.00', 'birth_city_Cape Town': '0.03', 'birth_city_Carlisle': '0.01', 'birth_city_Carshalton': '0.01', 'birth_city_Chatham': '0.00', 'birth_city_Chelmsford': '0.00', 'birth_city_Cheltenham': '0.00', 'birth_city_Chertsey': '0.00', 'birth_city_Cheshunt': '0.00', 'birth_city_Chester': '0.01', 'birth_city_ChesterNaNleNaNStreet': '0.05', 'birth_city_Chesterfield': '0.02', 'birth_city_Chichester': '0.01', 'birth_city_Chigwell': '0.00', 'birth_city_Cinderford': '0.00', 'birth_city_Clevedon': '0.00', 'birth_city_Coalville': '0.00', 'birth_city_Colchester': '0.00', 'birth_city_Consett': '0.00', 'birth_city_Coventry': '0.01', 'birth_city_Cowes': '0.00', 'birth_city_Crawley': '0.00', 'birth_city_Crewe': '0.00', 'birth_city_Crosby': '0.00', 'birth_city_Croydon': '0.00', 'birth_city_Dagenham': '0.00', 'birth_city_Darlington': '0.00', 'birth_city_Dartford': '0.00', 'birth_city_Daventry': '0.00', 'birth_city_Derby': '0.00', 'birth_city_Dewsbury': '0.00', 'birth_city_Doncaster': '0.00', 'birth_city_Dorchester': '0.00', 'birth_city_Douglas [Isle Of Man]': '0.00', 'birth_city_Droylsden': '0.00', 'birth_city_Dublin': '0.00', 'birth_city_Dudley': '0.00', 'birth_city_Durham': '0.00', 'birth_city_Ealing': '0.00', 'birth_city_East Grinstead': '0.00', 'birth_city_Eastbourne': '0.00', 'birth_city_Eastleigh': '0.00', 'birth_city_Edgbaston': '0.00', 'birth_city_Eisenstadt': '0.01', 'birth_city_Enfield': '0.05', 'birth_city_Epsom': '0.00', 'birth_city_Exeter': '0.03', 'birth_city_Exmouth': '0.00', 'birth_city_Farnborough': '0.00', 'birth_city_Felixstowe': '0.00', 'birth_city_Forest Gate': '0.02', 'birth_city_Freetown': '0.00', 'birth_city_Garstang': '0.00', 'birth_city_Gateshead': '0.00', 'birth_city_Gillingham': '0.00', 'birth_city_Gloucester': '0.00', 'birth_city_Goole': '0.00', 'birth_city_Gorleston on Sea': '0.00', 'birth_city_Gosport': '0.00', 'birth_city_Grantham': '0.00', 'birth_city_Gravesend': '0.00', 'birth_city_Great Yarmouth': '0.00', 'birth_city_Grimsby': '0.00', 'birth_city_Guernsey': '0.00', 'birth_city_Guildford': '0.00', 'birth_city_Guisborough': '0.00', 'birth_city_Halesowen': '0.00', 'birth_city_Halifax': '0.00', 'birth_city_Hamilton': '0.00', 'birth_city_Harlow': '0.01', 'birth_city_Harrogate': '0.04', 'birth_city_Harrow': '0.01', 'birth_city_Hartlepool': '0.01', 'birth_city_Hastings': '0.00', 'birth_city_Havant': '0.00', 'birth_city_Haywards Heath': '0.00', 'birth_city_Hebburn': '0.00', 'birth_city_Hednesford': '0.01', 'birth_city_Hemel Hempstead': '0.00', 'birth_city_Hereford': '0.00', 'birth_city_Hexham': '0.00', 'birth_city_High Wycombe': '0.01', 'birth_city_Hillingdon': '0.00', 'birth_city_Hitchin': '0.00', 'birth_city_Hook Norton': '0.00', 'birth_city_Horsham': '0.03', 'birth_city_Hounslow': '0.00', 'birth_city_Huddersfield': '0.00', 'birth_city_Hull': '0.00', 'birth_city_Huntingdon': '0.01', 'birth_city_Huyton': '0.00', 'birth_city_Hyde': '0.00', 'birth_city_Ibadan': '0.00', 'birth_city_Ilford': '0.01', 'birth_city_Ipswich': '0.00', 'birth_city_Isleworth': '0.01', 'birth_city_Jarrow': '0.02', 'birth_city_Jersey': '0.00', 'birth_city_Keighley': '0.00', 'birth_city_Kidderminster': '0.00', 'birth_city_Kidlington': '0.02', \"birth_city_King's Lynn\": '0.00', 'birth_city_Kingston': '0.00', 'birth_city_Kingston upon Thames': '0.00', 'birth_city_Kinshasa': '0.00', 'birth_city_Kuching (Srw)': '0.00', 'birth_city_Kumasi': '0.00', 'birth_city_Lancaster': '0.00', 'birth_city_Leamington Spa': '0.00', 'birth_city_Leeds': '0.00', 'birth_city_Leicester': '0.03', 'birth_city_Leighton Buzzard': '0.00', 'birth_city_Leyton': '0.00', 'birth_city_Lichfield': '0.00', 'birth_city_Lincoln': '0.00', 'birth_city_Lingfield': '0.00', 'birth_city_Liverpool': '0.01', 'birth_city_London': '0.10', 'birth_city_Loughborough': '0.00', 'birth_city_Luanda': '0.00', 'birth_city_Ludlow': '0.00', 'birth_city_Luton': '0.00', 'birth_city_Maidenhead': '0.00', 'birth_city_Maidstone': '0.00', 'birth_city_Manchester': '0.01', 'birth_city_Mansfield': '0.00', 'birth_city_Market Drayton': '0.00', 'birth_city_Market Harborough': '0.00', 'birth_city_Matosinhos': '0.00', 'birth_city_Middlesbrough': '0.00', 'birth_city_Milton Keynes': '0.00', 'birth_city_Montego Bay': '0.00', 'birth_city_Moscow': '0.02', 'birth_city_Nantwich': '0.00', 'birth_city_Newcastle': '0.00', 'birth_city_NewcastleNaNunderNaNLyme': '0.00', 'birth_city_Newport (Isle of Wight)': '0.00', 'birth_city_Newton Aycliffe': '0.00', 'birth_city_North Shields': '0.00', 'birth_city_Northallerton': '0.00', 'birth_city_Northampton': '0.00', 'birth_city_Northfleet': '0.00', 'birth_city_Norwich': '0.00', 'birth_city_Nottingham': '0.00', 'birth_city_Nuneaton': '0.01', 'birth_city_Oakville (ON)': '0.00', 'birth_city_Oldham': '0.00', 'birth_city_Ollerton': '0.00', 'birth_city_Ormskirk': '0.00', 'birth_city_Orpington': '0.00', 'birth_city_Oxford': '0.02', 'birth_city_Paris': '0.00', 'birth_city_Peterborough': '0.00', 'birth_city_Petersfield': '0.00', 'birth_city_Plymouth': '0.02', 'birth_city_Pontefract': '0.00', 'birth_city_Poole': '0.00', 'birth_city_Portsmouth': '0.02', 'birth_city_Preston': '0.00', 'birth_city_Pretoria': '0.00', 'birth_city_Ramsbottom': '0.00', 'birth_city_Reading': '0.02', 'birth_city_Redcar': '0.00', 'birth_city_Redditch': '0.01', 'birth_city_Redhill': '0.00', 'birth_city_Richmond': '0.00', 'birth_city_Ripon': '0.00', 'birth_city_Rochdale': '0.01', 'birth_city_Rochester': '0.00', 'birth_city_Romford': '0.00', 'birth_city_Rotherham': '0.00', 'birth_city_Salford': '0.01', 'birth_city_Salisbury': '0.00', 'birth_city_Scunthorpe': '0.00', 'birth_city_Sedgefield': '0.00', 'birth_city_Selby': '0.00', 'birth_city_Sheffield': '0.00', 'birth_city_Shrewsbury': '0.01', 'birth_city_Sidcup': '0.00', 'birth_city_Slough': '0.04', 'birth_city_Solihull': '0.00', 'birth_city_South Shields': '0.00', 'birth_city_Southampton': '0.00', 'birth_city_SouthendNaNonNaNSea': '0.00', 'birth_city_Southport': '0.00', 'birth_city_Southwark': '0.00', 'birth_city_St. Helens': '0.00', 'birth_city_Stafford': '0.00', 'birth_city_Stalybridge': '0.00', 'birth_city_Stevenage': '0.00', 'birth_city_Stockport': '0.00', 'birth_city_StocktonNaNonNaNTees': '0.01', 'birth_city_StokeNaNonNaNTrent': '0.00', 'birth_city_Stourbridge': '0.00', 'birth_city_Sunderland': '0.00', 'birth_city_Sutton': '0.00', 'birth_city_Sutton Coldfield': '0.00', 'birth_city_Swindon': '0.00', 'birth_city_Tamworth': '0.00', 'birth_city_Taunton': '0.00', 'birth_city_Telford': '0.00', 'birth_city_Thurrock': '0.00', 'birth_city_Tiverton': '0.00', 'birth_city_Torquay': '0.00', 'birth_city_Trowbridge': '0.00', 'birth_city_Truro': '0.01', 'birth_city_Uckfield': '0.00', 'birth_city_Urmston': '0.00', 'birth_city_Vancouver (BC)': '0.01', 'birth_city_Wakefield': '0.00', 'birth_city_Walsall': '0.02', 'birth_city_Walthamstow': '0.04', 'birth_city_Wantage': '0.00', 'birth_city_Warrington': '0.06', 'birth_city_Warwick': '0.00', 'birth_city_Washington': '0.00', 'birth_city_Waterlooville': '0.00', 'birth_city_Watford': '0.00', 'birth_city_Wellingborough': '0.00', 'birth_city_Welwyn Garden City': '0.00', 'birth_city_West Bromwich': '0.00', 'birth_city_Weybridge': '0.00', 'birth_city_Weymouth': '0.00', 'birth_city_Whiston': '0.00', 'birth_city_Whitchurch (Hampshire)': '0.01', 'birth_city_Whitehaven': '0.01', 'birth_city_Whitley Bay': '0.00', 'birth_city_Whitstable': '0.00', 'birth_city_Wigan': '0.00', 'birth_city_Winchester': '0.00', 'birth_city_Winsford': '0.00', 'birth_city_Wisbech': '0.00', 'birth_city_Woking': '0.00', 'birth_city_Wolverhampton': '0.00', 'birth_city_Worthing': '0.01', 'birth_city_Yaound': '0.00', 'birth_city_Yeovil': '0.00', 'birth_city_York': '0.01', 'nation_of_birth_ANG': '0.00', 'nation_of_birth_AUT': '0.02', 'nation_of_birth_BER': '0.00', 'nation_of_birth_CAN': '0.01', 'nation_of_birth_CIV': '0.00', 'nation_of_birth_CMR': '0.01', 'nation_of_birth_COD': '0.01', 'nation_of_birth_ENG': '0.03', 'nation_of_birth_FRA': '0.00', 'nation_of_birth_GHA': '0.01', 'nation_of_birth_GNB': '0.00', 'nation_of_birth_IRL': '0.00', 'nation_of_birth_JAM': '0.00', 'nation_of_birth_MAS': '0.00', 'nation_of_birth_NED': '0.00', 'nation_of_birth_NGA': '0.00', 'nation_of_birth_POR': '0.00', 'nation_of_birth_RSA': '0.00', 'nation_of_birth_RUS': '0.00', 'nation_of_birth_SLE': '0.00', 'birth_region_Caribbean': '0.00', 'birth_region_Central Africa': '0.00', 'birth_region_Central Europe': '0.00', 'birth_region_North America': '0.00', 'birth_region_North Eastern Europe': '0.00', 'birth_region_Southeast Asia': '0.00', 'birth_region_Southern Africa': '0.00', 'birth_region_UK & Ireland': '0.03', 'birth_region_Western Africa': '0.01', 'birth_region_Western Europe': '0.00', 'nationality_ENG': '0.00', 'position_AM (C)': '0.02', 'position_AM (C), ST (C)': '0.05', 'position_AM (L)': '0.00', 'position_AM (L), ST (C)': '0.08', 'position_AM (LC)': '0.00', 'position_AM (LC), ST (C)': '0.00', 'position_AM (R)': '0.00', 'position_AM (R), ST (C)': '0.02', 'position_AM (RC)': '0.01', 'position_AM (RC), ST (C)': '0.01', 'position_AM (RL)': '0.04', 'position_AM (RL), ST (C)': '0.00', 'position_AM (RLC)': '0.00', 'position_AM (RLC), ST (C)': '0.02', 'position_D (C)': '0.04', 'position_D (C), DM': '0.00', 'position_D (C), DM, M (C)': '0.00', 'position_D (L)': '0.01', 'position_D (L), M (C)': '0.00', 'position_D (LC)': '0.00', 'position_D (LC), WB (L)': '0.00', 'position_D (LC), WB/M (L)': '0.00', 'position_D (R)': '0.01', 'position_D (R), DM, M (C)': '0.00', 'position_D (R), M (C)': '0.00', 'position_D (R), WB (RL), DM, M (C)': '0.00', 'position_D (RC)': '0.03', 'position_D (RC), DM': '0.00', 'position_D (RC), WB (R)': '0.00', 'position_D (RL)': '0.00', 'position_D (RL), DM, M (C)': '0.00', 'position_D (RL), WB (L)': '0.00', 'position_D (RL), WB (R)': '0.00', 'position_D (RLC)': '0.00', 'position_D (RLC), WB (RL)': '0.00', 'position_D/M (C)': '0.00', 'position_D/WB (L)': '0.02', 'position_D/WB (L), M (C)': '0.00', 'position_D/WB (R)': '0.00', 'position_D/WB (R), DM': '0.00', 'position_D/WB (R), DM, M (C)': '0.00', 'position_D/WB (R), M (C)': '0.00', 'position_D/WB (RL)': '0.00', 'position_D/WB/M (L)': '0.00', 'position_D/WB/M (R)': '0.00', 'position_D/WB/M/AM (L)': '0.00', 'position_D/WB/M/AM (R)': '0.04', 'position_DM': '0.00', 'position_DM, M (C)': '0.07', 'position_DM, M (RC)': '0.00', 'position_DM, M (RC), AM (R)': '0.00', 'position_DM, M/AM (C)': '0.08', 'position_GK': '0.01', 'position_M (C)': '0.09', 'position_M (C), AM (LC)': '0.00', 'position_M (C), AM (LC), ST (C)': '0.00', 'position_M (C), AM (R)': '0.00', 'position_M (C), AM (RC)': '0.00', 'position_M (C), AM (RLC)': '0.00', 'position_M (L)': '0.00', 'position_M (L), AM (LC)': '0.00', 'position_M (L), AM (RL)': '0.00', 'position_M (L), AM (RLC)': '0.00', 'position_M (LC)': '0.00', 'position_M (LC), AM (L)': '0.00', 'position_M (LC), AM (RLC)': '0.00', 'position_M (R), AM (L)': '0.00', 'position_M (R), AM (RC)': '0.00', 'position_M (R), AM (RL)': '0.00', 'position_M (R), AM (RLC)': '0.00', 'position_M (RC)': '0.00', 'position_M (RC), AM (C)': '0.00', 'position_M (RL), AM (RLC)': '0.09', 'position_M (RLC), AM (C)': '0.00', 'position_M/AM (C)': '0.00', 'position_M/AM (L)': '0.00', 'position_M/AM (R)': '0.02', 'position_M/AM (RL)': '0.00', 'position_ST (C)': '0.03', 'position_WB (L)': '0.00', 'position_WB (L), M (C)': '0.00', 'position_WB (L), M (LC), AM (R)': '0.00', 'position_WB (L), M (RL), AM (C)': '0.00', 'position_WB (R)': '0.00', 'position_WB (R), AM (RC)': '0.00', 'position_WB (R), M (C)': '0.00', 'position_WB (R), M (RC), AM (C)': '0.00', 'position_WB (R), M (RC), AM (R)': '0.00', 'position_WB (R), M/AM (RL)': '0.00', 'position_WB (RL)': '0.00', 'position_WB (RL), M (RC), AM (RL)': '0.00', 'position_WB/AM (L)': '0.00', 'position_WB/AM (R)': '0.00', 'position_WB/M (L)': '0.00', 'position_WB/M (R)': '0.00', 'position_WB/M (RL), AM (R)': '0.00', 'position_WB/M/AM (L)': '0.00', 'position_WB/M/AM (R)': '0.00', 'group_Defender': '0.05', 'group_Forward': '0.04', 'group_Goalkeeper': '0.00', 'group_Midfielder': '0.02', 'club_A. Baleares': '0.00', 'club_AA Gent': '0.00', 'club_AC Milan': '0.00', 'club_AC Oulu': '0.01', 'club_AEL': '0.00', 'club_AFC Croydon Athletic': '0.00', 'club_AFC Fylde': '0.32', 'club_AFC Wimbledon': '0.72', 'club_AS Roma': '0.00', 'club_ASSE': '0.00', 'club_AaB': '0.00', 'club_Aberdeen': '0.04', 'club_Aberystwyth': '0.00', 'club_Accrington': '1.12', 'club_Adelaide United': '0.01', 'club_Ahlen': '0.00', 'club_Airdrieonians': '0.00', 'club_Ajax': '0.04', 'club_Al-Bidda': '0.00', 'club_Al-Entesar Club': '0.00', 'club_Al-Khaleej (KSA)': '0.00', 'club_Al-Qadsiah': '0.00', 'club_Al-Shahaniya': '0.00', 'club_Al-Wakrah': '0.00', 'club_Albacete': '0.00', 'club_Aldershot': '0.59', 'club_Alloa': '0.00', 'club_Altrincham': '0.26', 'club_Amiens SC': '0.01', 'club_Annan Athletic': '0.01', 'club_Arbroath': '0.00', 'club_Aris Limassol': '0.00', 'club_Arsenal': '0.67', 'club_Asker': '0.00', 'club_Aston Villa': '0.14', 'club_Augsburg': '0.00', 'club_Ayr United': '0.00', 'club_Barnet': '0.09', 'club_Barnsley': '0.87', 'club_Barrow': '0.05', 'club_Bath City': '0.00', 'club_Baakehir FK': '0.00', 'club_Beerschot U23': '0.00', 'club_Bellshill': '0.00', 'club_Beikta': '0.00', 'club_Birmingham': '0.31', \"club_Bishop's Stortford\": '0.00', 'club_Blackburn': '0.16', 'club_Blackpool': '1.04', 'club_Blyth': '0.00', 'club_Bohemians': '0.00', 'club_Bolton': '0.83', 'club_Bootle': '0.00', 'club_Boreham Wood': '0.00', 'club_Borussia Dortmund': '0.00', 'club_Bournemouth': '0.57', 'club_Brackley': '0.00', 'club_Bradford City': '0.07', 'club_Braintree': '0.00', 'club_Brentford': '0.35', 'club_Brighton & Hove Albion': '0.01', 'club_Bristol City': '0.79', 'club_Bristol Rovers': '0.27', 'club_Bromley': '0.11', 'club_Brunswick Juventus': '0.00', 'club_Burnley': '0.09', 'club_Burton': '1.02', 'club_Buxton': '0.00', 'club_CC Mariners': '0.00', 'club_Cambridge': '0.55', 'club_Cape Town Spurs': '0.01', 'club_Cardiff': '0.17', 'club_Carlisle': '1.07', 'club_Carolina Core': '0.00', 'club_Castelln': '0.00', 'club_Cavalry FC': '0.00', 'club_Celtic': '0.00', 'club_Charleston': '0.01', 'club_Charlotte FC': '0.02', 'club_Charlton': '0.37', 'club_Chattanooga': '0.00', 'club_Chattanooga FC': '0.00', 'club_Chelsea': '0.73', 'club_Cheltenham': '0.12', 'club_Chennai': '0.00', 'club_Cheshunt': '0.00', 'club_Chesterfield': '0.05', 'club_Chorley': '0.00', 'club_Cliftonville': '0.00', 'club_Club NXT': '0.00', 'club_Colchester': '0.99', 'club_Coldstream': '0.00', 'club_Colorado': '0.00', \"club_Connah's Quay\": '0.00', 'club_Cove Rangers': '0.00', 'club_Coventry': '0.32', 'club_Crawley': '0.44', 'club_Cray': '0.00', 'club_Crewe': '0.19', 'club_Crystal Palace': '1.80', 'club_Dag & Red': '0.05', 'club_Dandenong Thunder': '0.00', 'club_Darlington': '0.00', 'club_Dartford': '0.00', 'club_Derby': '1.02', 'club_Derry City': '0.00', 'club_Detroit City': '0.01', 'club_Doncaster': '1.10', 'club_Dorking': '0.25', 'club_Doxa Katokopias': '0.01', 'club_Drogheda Utd': '0.00', 'club_Dundalk': '0.00', 'club_Dundee': '0.02', 'club_Dundee United': '0.00', 'club_Dunfermline Athletic': '0.00', 'club_East Kilbride': '0.00', 'club_Eastbourne Borough': '0.00', 'club_Eastleigh': '0.00', 'club_Ebbsfleet': '0.26', 'club_Elgin City': '0.00', 'club_Estrela da Amadora B': '0.00', 'club_Everton': '0.57', 'club_Exeter': '0.41', 'club_FC Admira Wacker Mdling': '0.00', 'club_FC Bayern': '0.00', 'club_FC Clifton Hill': '0.00', 'club_FC Halifax': '0.30', 'club_FC Porto': '0.02', 'club_FC United': '0.00', 'club_FC Villefranche': '0.00', 'club_FC Volendam': '0.00', 'club_Falkirk': '0.00', 'club_Farnborough': '0.00', 'club_Fenerbahe': '0.00', 'club_Fleetwood': '0.48', 'club_Forest Green': '0.09', 'club_Fulham': '0.00', 'club_Galway Utd': '0.00', 'club_Gateshead': '1.05', 'club_Genoa': '0.00', 'club_Getafe': '0.00', 'club_Gillingham': '0.56', 'club_Gosport': '0.00', 'club_Greenock Morton': '0.00', 'club_Gretna 2008': '0.02', 'club_Grimsby': '0.61', 'club_Grimsby Boro': '0.00', 'club_Halifax Wanderers FC': '0.00', 'club_Hapoel Acre': '0.01', 'club_Hapoel Petach-Tikva': '0.00', 'club_Harrogate': '0.25', 'club_Hartlepool': '0.26', 'club_Hashtag': '0.00', 'club_Hatayspor': '0.00', 'club_Havant & W': '0.00', 'club_Haverfordwest': '0.00', 'club_Hearts': '0.07', 'club_Heidelberg Utd': '0.00', 'club_Hemel Hempstead': '0.00', 'club_Hertha BSC': '0.01', 'club_Hibernian': '0.15', 'club_Huddersfield': '0.23', 'club_Hull': '0.14', 'club_Hungerford': '0.00', 'club_Huntly': '0.02', 'club_Huntsville': '0.00', 'club_Indy Eleven': '0.03', 'club_Inverness CT': '0.01', 'club_Ipswich': '0.12', 'club_Juventus': '0.01', 'club_KV Kortrijk': '0.00', 'club_Kedah': '0.00', 'club_Kidderminster': '0.14', 'club_Kilmarnock': '0.00', 'club_Kitchee': '0.00', 'club_Knoxville': '0.00', 'club_LOSC': '0.00', 'club_La Castellana': '0.00', 'club_Las Vegas': '0.00', 'club_Lausanne': '0.01', 'club_Leeds': '0.28', 'club_Leicester': '0.22', 'club_Leyton Orient': '0.55', 'club_Lincoln': '0.01', 'club_Linlithgow Rose': '0.00', 'club_Liverpool': '0.01', 'club_Livingston': '0.03', 'club_Loch Ness': '0.00', 'club_Lommel SK': '0.01', 'club_Louisville': '0.01', 'club_Luton': '0.50', 'club_MK Dons': '0.62', 'club_Madison': '0.03', 'club_Magdeburg': '0.02', 'club_Maidenhead': '0.05', 'club_Maidstone': '0.00', 'club_Man City': '0.01', 'club_Manchester United': '0.11', 'club_Mansfield': '0.07', 'club_Marine': '0.00', 'club_Mickleover': '0.00', 'club_Middlesbrough': '0.01', 'club_Millwall': '0.32', 'club_Morecambe': '0.14', 'club_Motherwell': '0.01', 'club_Nairn County': '0.00', 'club_Nashville': '0.01', 'club_New Mexico': '0.00', 'club_Newcastle': '0.37', 'club_Newport Co': '0.07', 'club_Northampton': '0.62', 'club_Northern Colorado': '0.00', 'club_Norwich': '0.14', 'club_Nottm Forest': '0.07', 'club_Notts Co': '0.71', 'club_Nrnberg': '0.00', 'club_OL': '0.03', 'club_Oakleigh Cannons': '0.01', 'club_Oldham': '0.11', 'club_Olympiacos': '0.03', 'club_Omaha': '0.00', 'club_Oostende': '0.00', 'club_Orange County': '0.01', 'club_Orihuela': '0.00', 'club_Oxford City': '0.01', 'club_Oxford United': '1.30', 'club_PAS Giannina': '0.00', 'club_Panserraikos': '0.01', 'club_Partick Thistle': '0.00', 'club_Peterborough': '0.54', 'club_Peterborough Sports': '0.00', 'club_Philadelphia': '0.01', 'club_Phoenix': '0.00', 'club_Phnix Lbeck': '0.00', 'club_Plymouth': '0.30', 'club_Plymouth Parkway': '0.00', 'club_Politehnica Iai': '0.00', 'club_Pollok': '0.00', 'club_Port Vale': '0.00', 'club_Portsmouth': '0.67', 'club_Preston': '0.02', 'club_Preston Athletic': '0.00', 'club_Pusks Akadmia': '0.00', 'club_QPR': '0.03', 'club_Queen of the South': '0.02', \"club_Queen's Park\": '0.01', 'club_R. Madrid': '0.00', 'club_RWD Molenbeek': '0.00', 'club_Rangers': '0.15', 'club_Raufoss': '0.00', 'club_Reading': '0.07', 'club_Real Salt Lake': '0.00', 'club_Richmond': '0.00', 'club_Robina City': '0.00', 'club_Rochdale': '0.00', 'club_Ross County': '0.27', 'club_Rotherham': '0.43', 'club_Royston': '0.00', 'club_SK Austria Klagenfurt': '0.00', 'club_SL16 FC': '0.00', 'club_SV Wehen Wiesbaden': '0.01', 'club_Sacramento': '0.00', 'club_Salford': '0.03', 'club_Sampdoria': '0.01', 'club_Scarborough Athletic': '0.00', 'club_Schalke 04': '0.00', 'club_Scunthorpe': '0.00', 'club_Seattle': '0.00', 'club_Sheff Utd': '0.14', 'club_Sheffield Wednesday': '0.08', 'club_Shelbourne': '0.00', 'club_Sheriff Tiraspol': '0.00', 'club_Shrewsbury': '0.06', 'club_Sligo Rovers': '0.00', 'club_Solihull Moors': '0.13', 'club_Southampton': '0.45', 'club_Southend': '0.19', 'club_Spartans': '0.00', 'club_Spennymoor': '0.00', 'club_Spokane': '0.00', 'club_Sporting CP': '0.02', 'club_St Johnstone': '0.00', 'club_St Mirren': '0.06', 'club_St. Albans': '0.00', 'club_St. Duthus': '0.00', \"club_St. Pat's Athletic\": '0.00', 'club_St. Pauli': '0.00', 'club_Stalybridge': '0.00', 'club_Standard': '0.01', 'club_Stevenage': '0.14', 'club_Stirling': '0.00', 'club_Stirling Uni': '0.00', 'club_Stockport': '0.75', 'club_Stoke': '0.10', 'club_Stourbridge': '0.00', 'club_Stratford': '0.00', 'club_Sunderland': '0.40', 'club_Sutton': '0.90', 'club_Swansea': '0.35', 'club_Swindon': '0.39', 'club_TNS': '0.00', 'club_Talavera': '0.00', 'club_Tampa Bay': '0.03', 'club_Tamworth': '0.00', 'club_Toronto FC II': '0.00', 'club_Torquay': '0.00', 'club_Torremolinos': '0.00', 'club_Tottenham': '0.00', 'club_Totton': '0.00', 'club_Tranmere': '0.19', 'club_Truro': '0.00', 'club_Tulsa': '0.00', 'club_Udinese': '0.01', 'club_Union SG': '0.01', 'club_VAFC': '0.01', 'club_Valour FC': '0.01', 'club_Vancouver 2': '0.00', 'club_Vancouver FC': '0.00', 'club_Vejle': '0.01', 'club_Walsall': '0.69', 'club_Warrington': '0.00', 'club_Warrington Rylands': '0.00', 'club_Waterford': '0.00', 'club_Watford': '0.00', 'club_Wealdstone': '0.20', 'club_Welling': '0.00', 'club_West Brom': '0.46', 'club_West Ham': '0.06', 'club_Weston-super-Mare': '0.00', 'club_Whitley Bay': '0.00', 'club_Wick Acad': '0.00', 'club_Wigan': '0.58', 'club_Woking': '0.33', 'club_Wolves': '0.00', 'club_Worthing': '0.00', 'club_Wrexham': '0.25', 'club_Wycombe': '0.51', 'club_York': '0.84', 'club_stanbulspor': '0.00', 'club_anlurfaspor': '0.00', 'second_nationality_ALB': '0.00', 'second_nationality_ALG': '0.01', 'second_nationality_ANG': '0.00', 'second_nationality_ATG': '0.00', 'second_nationality_AUS': '0.00', 'second_nationality_BAN': '0.00', 'second_nationality_BDI': '0.00', 'second_nationality_BEL': '0.00', 'second_nationality_BER': '0.01', 'second_nationality_BRB': '0.00', 'second_nationality_CAN': '0.01', 'second_nationality_CIV': '0.01', 'second_nationality_CMR': '0.04', 'second_nationality_COD': '0.05', 'second_nationality_COL': '0.00', 'second_nationality_CPV': '0.00', 'second_nationality_CRO': '0.00', 'second_nationality_CYP': '0.06', 'second_nationality_CZE': '0.00', 'second_nationality_DMA': '0.00', 'second_nationality_ECU': '0.00', 'second_nationality_ERI': '0.00', 'second_nationality_ESP': '0.00', 'second_nationality_FRA': '0.00', 'second_nationality_GAM': '0.00', 'second_nationality_GER': '0.02', 'second_nationality_GHA': '0.01', 'second_nationality_GNB': '0.00', 'second_nationality_GRN': '0.01', 'second_nationality_GUI': '0.00', 'second_nationality_GUY': '0.00', 'second_nationality_HKG': '0.00', 'second_nationality_IND': '0.01', 'second_nationality_IRL': '0.02', 'second_nationality_ISR': '0.00', 'second_nationality_ITA': '0.00', 'second_nationality_JAM': '0.01', 'second_nationality_KEN': '0.01', 'second_nationality_LBR': '0.00', 'second_nationality_LCA': '0.00', 'second_nationality_MAR': '0.00', 'second_nationality_MAS': '0.00', 'second_nationality_MLT': '0.00', 'second_nationality_MSR': '0.00', 'second_nationality_NED': '0.03', 'second_nationality_NGA': '0.06', 'second_nationality_NIR': '0.00', 'second_nationality_NOR': '0.00', 'second_nationality_NZL': '0.00', 'second_nationality_PAK': '0.01', 'second_nationality_PHI': '0.00', 'second_nationality_POL': '0.00', 'second_nationality_POR': '0.00', 'second_nationality_RSA': '0.00', 'second_nationality_RUS': '0.00', 'second_nationality_SCO': '0.02', 'second_nationality_SGP': '0.00', 'second_nationality_SKN': '0.00', 'second_nationality_SLE': '0.00', 'second_nationality_TRI': '0.00', 'second_nationality_TUR': '0.00', 'second_nationality_UGA': '0.03', 'second_nationality_USA': '0.01', 'second_nationality_VEN': '0.00', 'second_nationality_WAL': '0.01', 'second_nationality_ZAM': '0.00', 'second_nationality_ZIM': '0.01'}\n",
      "2024-08-14 13:47:32,063 - INFO - Predictions have been saved to 'predictions_2024_youth.csv'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score, classification_report\n",
    "from sklearn.model_selection import RandomizedSearchCV, train_test_split\n",
    "import logging\n",
    "import numpy as np\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "def load_data(file_path):\n",
    "    try:\n",
    "        data = pd.read_csv(file_path)\n",
    "        logging.info(f\"Dataset {file_path} loaded successfully.\")\n",
    "        return data\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error loading dataset {file_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "def preprocess_data(data, age_column_name, all_columns=None):\n",
    "    data = data.copy()\n",
    "\n",
    "    # Filter out players born before a certain date (e.g., before 1993)\n",
    "    if 'date_of_birth' in data.columns:\n",
    "        cutoff_date = pd.to_datetime('1993-01-01')\n",
    "        data['date_of_birth'] = pd.to_datetime(data['date_of_birth'], errors='coerce')\n",
    "        data = data[data['date_of_birth'] >= cutoff_date]\n",
    "\n",
    "    # One-Hot Encoding for nominal categorical variables\n",
    "    nominal_columns = ['based_in', 'birth_city', 'nation_of_birth', 'birth_region', 'nationality', \n",
    "                       'position', 'group', 'club', 'second_nationality']\n",
    "    \n",
    "    # Apply One-Hot Encoding\n",
    "    data = pd.get_dummies(data, columns=nominal_columns)\n",
    "\n",
    "    # Align with all_columns if provided\n",
    "    if all_columns is not None:\n",
    "        for col in all_columns:\n",
    "            if col not in data.columns:\n",
    "                data[col] = 0\n",
    "        data = data[all_columns]  # Ensure same order\n",
    "\n",
    "    # Label Encoding for ordinal or binary categorical variables\n",
    "    label_encoders = {}\n",
    "    ordinal_columns = ['division', 'division_tier', 'is_top_4_tier']\n",
    "\n",
    "    for col in ordinal_columns:\n",
    "        if col in data.columns:\n",
    "            le = LabelEncoder()\n",
    "            data[col] = le.fit_transform(data[col].astype(str))\n",
    "            label_encoders[col] = le\n",
    "\n",
    "    # Handle missing values - fill NaNs with a placeholder (e.g., -1) or the median for numerical columns\n",
    "    data.fillna(-1, inplace=True)\n",
    "\n",
    "    return data, label_encoders\n",
    "\n",
    "def filter_goalkeepers(data):\n",
    "    # Assuming 'group_2' identifies goalkeepers after one-hot encoding\n",
    "    if 'group_2' in data.columns:\n",
    "        data = data[data['group_2'] != 1]  # Exclude rows where group_2 is 1 (indicating goalkeepers)\n",
    "    return data\n",
    "\n",
    "\n",
    "\n",
    "def prepare_features_and_targets(data, age_column_name):\n",
    "    # Selecting the features that are numeric and relevant\n",
    "    features = data.drop(columns=['goals', 'appearances', 'tier_quality', 'name', 'date_of_birth'])  # Drop any columns that are not features or need to be excluded\n",
    "\n",
    "    target_goals = data['goals'].astype(int)\n",
    "    target_appearances = data['appearances'].astype(int)\n",
    "    target_tier_quality = data['tier_quality']\n",
    "\n",
    "    X = features\n",
    "    y_goals = target_goals\n",
    "    y_appearances = target_appearances\n",
    "    y_tier_quality = target_tier_quality\n",
    "\n",
    "    return X, y_goals, y_appearances, y_tier_quality\n",
    "\n",
    "\n",
    "# def tune_hyperparameters(X_train, y_train, is_classifier=False):\n",
    "#     param_distributions = {\n",
    "#         'n_estimators': np.arange(100, 1100, 100),\n",
    "#         'max_depth': [None] + list(np.arange(10, 51, 10)),\n",
    "#         'min_samples_split': [2, 5, 10, 15, 20],\n",
    "#         'min_samples_leaf': [1, 2, 5, 10]\n",
    "#     }\n",
    "\n",
    "def tune_hyperparameters(X_train, y_train, is_classifier=False):\n",
    "    param_distributions = {\n",
    "        'n_estimators': [10, 50, 100],  # Start with fewer trees\n",
    "        'max_depth': [5, 10],  # Limit the depth\n",
    "        'min_samples_split': [2, 5],\n",
    "        'min_samples_leaf': [1, 2]\n",
    "    }\n",
    "    \n",
    "    if is_classifier:\n",
    "        model = RandomForestClassifier(random_state=42)\n",
    "        scoring = 'accuracy'\n",
    "    else:\n",
    "        model = RandomForestRegressor(random_state=42)\n",
    "        scoring = 'neg_mean_squared_error'\n",
    "    \n",
    "    random_search = RandomizedSearchCV(estimator=model, param_distributions=param_distributions, \n",
    "                                       n_iter=100, cv=5, n_jobs=-1, verbose=2, scoring=scoring, random_state=42)\n",
    "    \n",
    "    random_search.fit(X_train, y_train)\n",
    "    logging.info(f\"Best parameters: {random_search.best_params_}\")\n",
    "    return random_search.best_estimator_\n",
    "\n",
    "def train_and_evaluate(X_train, y_train_goals, y_train_appearances, y_train_tier_quality, X_val, y_val_goals, y_val_appearances, y_val_tier_quality):\n",
    "    # Tune hyperparameters for goals prediction\n",
    "    best_rf_goals = tune_hyperparameters(X_train, y_train_goals)\n",
    "    best_rf_goals.fit(X_train, y_train_goals)\n",
    "\n",
    "    # Tune hyperparameters for appearances prediction\n",
    "    best_rf_appearances = tune_hyperparameters(X_train, y_train_appearances)\n",
    "    best_rf_appearances.fit(X_train, y_train_appearances)\n",
    "\n",
    "    # Tune hyperparameters for tier quality prediction\n",
    "    best_rf_tier_quality = tune_hyperparameters(X_train, y_train_tier_quality, is_classifier=True)\n",
    "    best_rf_tier_quality.fit(X_train, y_train_tier_quality)\n",
    "\n",
    "    # Evaluate the models on validation set\n",
    "    y_val_pred_goals = best_rf_goals.predict(X_val)\n",
    "    y_val_pred_appearances = best_rf_appearances.predict(X_val)\n",
    "    y_val_pred_tier_quality = best_rf_tier_quality.predict(X_val)\n",
    "\n",
    "    logging.info(f'Validation MSE Goals: {mean_squared_error(y_val_goals, y_val_pred_goals):.0f}')\n",
    "    logging.info(f'Validation MSE Appearances: {mean_squared_error(y_val_appearances, y_val_pred_appearances):.0f}')\n",
    "    logging.info(f'Validation Accuracy Tier Quality: {accuracy_score(y_val_tier_quality, y_val_pred_tier_quality)}')\n",
    "    logging.info(f'Validation Classification Report Tier Quality:\\n{classification_report(y_val_tier_quality, y_val_pred_tier_quality)}')\n",
    "\n",
    "    return best_rf_goals, best_rf_appearances, best_rf_tier_quality\n",
    "\n",
    "def evaluate_models(best_rf_goals, best_rf_appearances, best_rf_tier_quality, X_test, y_test_goals, y_test_appearances, y_test_tier_quality):\n",
    "    # Make predictions on the testing set\n",
    "    y_pred_goals = best_rf_goals.predict(X_test)\n",
    "    y_pred_appearances = best_rf_appearances.predict(X_test)\n",
    "    y_pred_tier_quality = best_rf_tier_quality.predict(X_test)\n",
    "\n",
    "    # Evaluate the models\n",
    "    mse_goals = mean_squared_error(y_test_goals, y_pred_goals)\n",
    "    mse_appearances = mean_squared_error(y_test_appearances, y_pred_appearances)\n",
    "    accuracy_tier_quality = accuracy_score(y_test_tier_quality, y_pred_tier_quality)\n",
    "\n",
    "    logging.info(f'MSE Goals: {mse_goals:.0f}')\n",
    "    logging.info(f'MSE Appearances: {mse_appearances:.0f}')\n",
    "    logging.info(f'Accuracy Tier Quality: {accuracy_tier_quality}')\n",
    "    logging.info(f'Test Classification Report Tier Quality:\\n{classification_report(y_test_tier_quality, y_pred_tier_quality)}')\n",
    "\n",
    "    # Convert feature importances to percentages\n",
    "    feature_names = X_test.columns  # Get feature names\n",
    "    goals_feature_importances = best_rf_goals.feature_importances_ * 100\n",
    "    appearances_feature_importances = best_rf_appearances.feature_importances_ * 100\n",
    "    tier_quality_feature_importances = best_rf_tier_quality.feature_importances_ * 100\n",
    "\n",
    "    # Pair feature names with their importance percentages, formatted to 2 decimal places\n",
    "    goals_importances_with_names = {name: f'{imp:.2f}' for name, imp in zip(feature_names, goals_feature_importances)}\n",
    "    appearances_importances_with_names = {name: f'{imp:.2f}' for name, imp in zip(feature_names, appearances_feature_importances)}\n",
    "    tier_quality_importances_with_names = {name: f'{imp:.2f}' for name, imp in zip(feature_names, tier_quality_feature_importances)}\n",
    "\n",
    "    # Log the feature importances with names\n",
    "    logging.info(f'Feature importances for goals (as percentages): {goals_importances_with_names}')\n",
    "    logging.info(f'Feature importances for appearances (as percentages): {appearances_importances_with_names}')\n",
    "    logging.info(f'Feature importances for tier quality (as percentages): {tier_quality_importances_with_names}')\n",
    "\n",
    "    return y_pred_goals, y_pred_appearances, y_pred_tier_quality\n",
    "\n",
    "def save_predictions(original_data, X_test, y_pred_goals, y_pred_appearances, y_pred_tier_quality, output_file):\n",
    "    # Filter the original data to match the X_test indices\n",
    "    filtered_original_data = original_data.loc[X_test.index]\n",
    "\n",
    "    # Reconstruct the 'group' column if necessary\n",
    "    group_columns = [col for col in filtered_original_data.columns if col.startswith('group_')]\n",
    "    if group_columns:\n",
    "        filtered_original_data['group'] = filtered_original_data[group_columns].idxmax(axis=1).str.replace('group_', '')\n",
    "\n",
    "    # Create predictions DataFrame\n",
    "    predictions = pd.DataFrame({\n",
    "        'name': filtered_original_data['name'],\n",
    "        'position': filtered_original_data['position'],\n",
    "        'group': filtered_original_data['group'],\n",
    "        'date_of_birth': filtered_original_data['date_of_birth'],\n",
    "        'birth_month': filtered_original_data['birth_month'],\n",
    "        'birth_quarter': filtered_original_data['birth_quarter'],  \n",
    "        'appearances_pred': np.round(y_pred_appearances, 0).astype(int),\n",
    "        'goals_pred': np.round(y_pred_goals, 0).astype(int),\n",
    "        'tier_pred': y_pred_tier_quality\n",
    "    })\n",
    "    \n",
    "    # Save predictions to CSV\n",
    "    predictions.to_csv(output_file, index=False)\n",
    "    logging.info(f\"Predictions have been saved to '{output_file}'.\")\n",
    "\n",
    "def main():\n",
    "    # Load and preprocess the 2016 senior players dataset\n",
    "    data_senior_2016 = load_data('dataset_2016_senior_players.csv')\n",
    "    if data_senior_2016 is not None:\n",
    "        logging.info(f\"Columns in the 2016 senior dataset: {data_senior_2016.columns.tolist()}\")\n",
    "        data_senior_preprocessed_2016, _ = preprocess_data(data_senior_2016, 'age_(months)_on_1_july_2015')\n",
    "        \n",
    "        # Filter out goalkeepers after preprocessing\n",
    "        data_senior_preprocessed_2016 = filter_goalkeepers(data_senior_preprocessed_2016)\n",
    "\n",
    "        # Capture all column names after preprocessing the training data\n",
    "        all_columns_2016 = data_senior_preprocessed_2016.columns.tolist()\n",
    "\n",
    "        # Prepare features and targets for the senior dataset (training)\n",
    "        X_senior_2016, y_goals_senior_2016, y_appearances_senior_2016, y_tier_quality_senior_2016 = prepare_features_and_targets(data_senior_preprocessed_2016, 'age_(months)_on_1_july_2015')\n",
    "        \n",
    "        # Split the senior dataset into training and validation sets\n",
    "        X_train_senior_2016, X_val_senior_2016, y_train_goals_senior_2016, y_val_goals_senior_2016, y_train_appearances_senior_2016, y_val_appearances_senior_2016, y_train_tier_quality_senior_2016, y_val_tier_quality_senior_2016 = train_test_split(\n",
    "            X_senior_2016, y_goals_senior_2016, y_appearances_senior_2016, y_tier_quality_senior_2016, test_size=0.2, random_state=42)\n",
    "        \n",
    "        # Train the models on the senior dataset and evaluate on the validation set\n",
    "        best_rf_goals_2016, best_rf_appearances_2016, best_rf_tier_quality_2016 = train_and_evaluate(\n",
    "            X_train_senior_2016, y_train_goals_senior_2016, y_train_appearances_senior_2016, y_train_tier_quality_senior_2016,\n",
    "            X_val_senior_2016, y_val_goals_senior_2016, y_val_appearances_senior_2016, y_val_tier_quality_senior_2016)\n",
    "\n",
    "    # Load and preprocess the 2016 youth players dataset\n",
    "    data_youth_2016 = load_data('dataset_2016_youth_players.csv')\n",
    "    if data_youth_2016 is not None:\n",
    "        logging.info(f\"Columns in the 2016 youth dataset: {data_youth_2016.columns.tolist()}\")\n",
    "        data_youth_preprocessed_2016, _ = preprocess_data(data_youth_2016, 'age_(months)_on_1_july_2015', all_columns=all_columns_2016)\n",
    "\n",
    "        # Filter out goalkeepers after preprocessing\n",
    "        data_youth_preprocessed_2016 = filter_goalkeepers(data_youth_preprocessed_2016)\n",
    "\n",
    "        # Prepare features and targets for the youth dataset (testing)\n",
    "        X_test_youth_2016, y_test_goals_youth_2016, y_test_appearances_youth_2016, y_test_tier_quality_youth_2016 = prepare_features_and_targets(data_youth_preprocessed_2016, 'age_(months)_on_1_july_2015')\n",
    "        \n",
    "        # Make predictions on the youth dataset using the models trained on the senior dataset\n",
    "        y_pred_goals_youth_2016, y_pred_appearances_youth_2016, y_pred_tier_quality_youth_2016 = evaluate_models(\n",
    "            best_rf_goals_2016, best_rf_appearances_2016, best_rf_tier_quality_2016, X_test_youth_2016, y_test_goals_youth_2016, y_test_appearances_youth_2016, y_test_tier_quality_youth_2016)\n",
    "\n",
    "        # Save predictions for the 2016 youth dataset\n",
    "        save_predictions(data_youth_2016, X_test_youth_2016, y_pred_goals_youth_2016, y_pred_appearances_youth_2016, y_pred_tier_quality_youth_2016, 'predictions_2016_youth.csv')\n",
    "\n",
    "    # Repeat the same process for the 2024 datasets\n",
    "\n",
    "    data_senior_2024 = load_data('dataset_2024_senior_players.csv')\n",
    "    if data_senior_2024 is not None:\n",
    "        logging.info(f\"Columns in the 2024 senior dataset: {data_senior_2024.columns.tolist()}\")\n",
    "        data_senior_preprocessed_2024, _ = preprocess_data(data_senior_2024, 'age_(months)_on_1_july_2023')\n",
    "        \n",
    "        # Filter out goalkeepers after preprocessing\n",
    "        data_senior_preprocessed_2024 = filter_goalkeepers(data_senior_preprocessed_2024)\n",
    "\n",
    "        # Capture all column names after preprocessing the training data\n",
    "        all_columns_2024 = data_senior_preprocessed_2024.columns.tolist()\n",
    "\n",
    "        # Prepare features and targets for the senior dataset (training)\n",
    "        X_senior_2024, y_goals_senior_2024, y_appearances_senior_2024, y_tier_quality_senior_2024 = prepare_features_and_targets(data_senior_preprocessed_2024, 'age_(months)_on_1_july_2023')\n",
    "        \n",
    "        # Split the senior dataset into training and validation sets\n",
    "        X_train_senior_2024, X_val_senior_2024, y_train_goals_senior_2024, y_val_goals_senior_2024, y_train_appearances_senior_2024, y_val_appearances_senior_2024, y_train_tier_quality_senior_2024, y_val_tier_quality_senior_2024 = train_test_split(\n",
    "            X_senior_2024, y_goals_senior_2024, y_appearances_senior_2024, y_tier_quality_senior_2024, test_size=0.2, random_state=42)\n",
    "        \n",
    "        # Train the models on the senior dataset and evaluate on the validation set\n",
    "        best_rf_goals_2024, best_rf_appearances_2024, best_rf_tier_quality_2024 = train_and_evaluate(\n",
    "            X_train_senior_2024, y_train_goals_senior_2024, y_train_appearances_senior_2024, y_train_tier_quality_senior_2024,\n",
    "            X_val_senior_2024, y_val_goals_senior_2024, y_val_appearances_senior_2024, y_val_tier_quality_senior_2024)\n",
    "\n",
    "    data_youth_2024 = load_data('dataset_2024_youth_players.csv')\n",
    "    if data_youth_2024 is not None:\n",
    "        logging.info(f\"Columns in the 2024 youth dataset: {data_youth_2024.columns.tolist()}\")\n",
    "        data_youth_preprocessed_2024, _ = preprocess_data(data_youth_2024, 'age_(months)_on_1_july_2023', all_columns=all_columns_2024)\n",
    "\n",
    "        # Filter out goalkeepers after preprocessing\n",
    "        data_youth_preprocessed_2024 = filter_goalkeepers(data_youth_preprocessed_2024)\n",
    "\n",
    "        # Prepare features and targets for the youth dataset (testing)\n",
    "        X_test_youth_2024, y_test_goals_youth_2024, y_test_appearances_youth_2024, y_test_tier_quality_youth_2024 = prepare_features_and_targets(data_youth_preprocessed_2024, 'age_(months)_on_1_july_2023')\n",
    "        \n",
    "        # Make predictions on the youth dataset using the models trained on the senior dataset\n",
    "        y_pred_goals_youth_2024, y_pred_appearances_youth_2024, y_pred_tier_quality_youth_2024 = evaluate_models(\n",
    "            best_rf_goals_2024, best_rf_appearances_2024, best_rf_tier_quality_2024, X_test_youth_2024, y_test_goals_youth_2024, y_test_appearances_youth_2024, y_test_tier_quality_youth_2024)\n",
    "\n",
    "        # Save predictions for the 2024 youth dataset\n",
    "        save_predictions(data_youth_2024, X_test_youth_2024, y_pred_goals_youth_2024, y_pred_appearances_youth_2024, y_pred_tier_quality_youth_2024, 'predictions_2024_youth.csv')\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
