{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error in Appearances Prediction: 119.09633027522936\n",
      "Mean Absolute Error in Goals Prediction: 11.545871559633028\n",
      "Mean Absolute Error in Tier Prediction: 2.055045871559633\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV files into pandas DataFrames\n",
    "predictions_2016 = pd.read_csv('predictions_2016_youth.csv')\n",
    "actuals_2024 = pd.read_csv('dataset_2024_senior_players.csv')\n",
    "\n",
    "# Ensure numeric columns are correctly parsed as numeric types\n",
    "predictions_2016['appearances_pred'] = pd.to_numeric(predictions_2016['appearances_pred'], errors='coerce')\n",
    "predictions_2016['goals_pred'] = pd.to_numeric(predictions_2016['goals_pred'], errors='coerce')\n",
    "predictions_2016['tier_pred'] = pd.to_numeric(predictions_2016['tier_pred'], errors='coerce')\n",
    "\n",
    "actuals_2024['appearances'] = pd.to_numeric(actuals_2024['appearances'], errors='coerce')\n",
    "actuals_2024['goals'] = pd.to_numeric(actuals_2024['goals'], errors='coerce')\n",
    "actuals_2024['tier_quality'] = pd.to_numeric(actuals_2024['tier_quality'], errors='coerce')\n",
    "\n",
    "# Merge the DataFrames on 'name' and 'date_of_birth'\n",
    "merged_df = pd.merge(predictions_2016, actuals_2024, on=['name', 'date_of_birth'])\n",
    "\n",
    "# Calculate differences\n",
    "merged_df['appearances_difference'] = merged_df['appearances'] - merged_df['appearances_pred']\n",
    "merged_df['goals_difference'] = merged_df['goals'] - merged_df['goals_pred']\n",
    "merged_df['tier_difference'] = merged_df['tier_quality'] - merged_df['tier_pred']\n",
    "\n",
    "# Save the comparison to a new CSV file\n",
    "comparison_file = 'comparison_results.csv'\n",
    "merged_df.to_csv(comparison_file, index=False)\n",
    "\n",
    "# Calculate mean absolute error for each metric\n",
    "mae_appearances = merged_df['appearances_difference'].abs().mean()\n",
    "mae_goals = merged_df['goals_difference'].abs().mean()\n",
    "mae_tier = merged_df['tier_difference'].abs().mean()\n",
    "\n",
    "print(f\"Mean Absolute Error in Appearances Prediction: {mae_appearances}\")\n",
    "print(f\"Mean Absolute Error in Goals Prediction: {mae_goals}\")\n",
    "print(f\"Mean Absolute Error in Tier Prediction: {mae_tier}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
